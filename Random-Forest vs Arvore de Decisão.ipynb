{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Random Forest (Floresta Aleatória)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregando a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = pd.read_csv('xAPI-Edu-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Good</td>\n",
       "      <td>Under-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>KW</td>\n",
       "      <td>KuwaIT</td>\n",
       "      <td>lowerlevel</td>\n",
       "      <td>G-04</td>\n",
       "      <td>A</td>\n",
       "      <td>IT</td>\n",
       "      <td>F</td>\n",
       "      <td>Father</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Above-7</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender NationalITy PlaceofBirth     StageID GradeID SectionID Topic  \\\n",
       "0      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "1      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "2      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "3      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "4      M          KW       KuwaIT  lowerlevel    G-04         A    IT   \n",
       "\n",
       "  Semester Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0        F   Father           15                16                  2   \n",
       "1        F   Father           20                20                  3   \n",
       "2        F   Father           10                 7                  0   \n",
       "3        F   Father           30                25                  5   \n",
       "4        F   Father           40                50                 12   \n",
       "\n",
       "   Discussion ParentAnsweringSurvey ParentschoolSatisfaction  \\\n",
       "0          20                   Yes                     Good   \n",
       "1          25                   Yes                     Good   \n",
       "2          30                    No                      Bad   \n",
       "3          35                    No                      Bad   \n",
       "4          50                    No                      Bad   \n",
       "\n",
       "  StudentAbsenceDays Class  \n",
       "0            Under-7     M  \n",
       "1            Under-7     M  \n",
       "2            Above-7     L  \n",
       "3            Above-7     L  \n",
       "4            Above-7     M  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando as distribuições de classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    211\n",
       "H    142\n",
       "L    127\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os registros nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                      0\n",
       "NationalITy                 0\n",
       "PlaceofBirth                0\n",
       "StageID                     0\n",
       "GradeID                     0\n",
       "SectionID                   0\n",
       "Topic                       0\n",
       "Semester                    0\n",
       "Relation                    0\n",
       "raisedhands                 0\n",
       "VisITedResources            0\n",
       "AnnouncementsView           0\n",
       "Discussion                  0\n",
       "ParentAnsweringSurvey       0\n",
       "ParentschoolSatisfaction    0\n",
       "StudentAbsenceDays          0\n",
       "Class                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edu.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codificando os atributos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = df_edu\n",
    "Cat_Colums = Features.dtypes.pipe(lambda Features: Features[Features=='object']).index\n",
    "for col in Cat_Colums:\n",
    "    label = LabelEncoder()\n",
    "    Features[col] = label.fit_transform(Features[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>NationalITy</th>\n",
       "      <th>PlaceofBirth</th>\n",
       "      <th>StageID</th>\n",
       "      <th>GradeID</th>\n",
       "      <th>SectionID</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Semester</th>\n",
       "      <th>Relation</th>\n",
       "      <th>raisedhands</th>\n",
       "      <th>VisITedResources</th>\n",
       "      <th>AnnouncementsView</th>\n",
       "      <th>Discussion</th>\n",
       "      <th>ParentAnsweringSurvey</th>\n",
       "      <th>ParentschoolSatisfaction</th>\n",
       "      <th>StudentAbsenceDays</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  NationalITy  PlaceofBirth  StageID  GradeID  SectionID  Topic  \\\n",
       "0       1            4             4        2        1          0      7   \n",
       "1       1            4             4        2        1          0      7   \n",
       "2       1            4             4        2        1          0      7   \n",
       "3       1            4             4        2        1          0      7   \n",
       "4       1            4             4        2        1          0      7   \n",
       "\n",
       "   Semester  Relation  raisedhands  VisITedResources  AnnouncementsView  \\\n",
       "0         0         0           15                16                  2   \n",
       "1         0         0           20                20                  3   \n",
       "2         0         0           10                 7                  0   \n",
       "3         0         0           30                25                  5   \n",
       "4         0         0           40                50                 12   \n",
       "\n",
       "   Discussion  ParentAnsweringSurvey  ParentschoolSatisfaction  \\\n",
       "0          20                      1                         1   \n",
       "1          25                      1                         1   \n",
       "2          30                      0                         0   \n",
       "3          35                      0                         0   \n",
       "4          50                      0                         0   \n",
       "\n",
       "   StudentAbsenceDays  Class  \n",
       "0                   1      2  \n",
       "1                   1      2  \n",
       "2                   0      1  \n",
       "3                   0      1  \n",
       "4                   0      2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando os dados e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df_edu.drop('Class',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df_edu['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest vs Árvore de Decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_clf = RandomForestClassifier(random_state=1,n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_random = cross_val_predict(random_clf, dataset, classes, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.65       142\n",
      "           1       0.77      0.78      0.77       127\n",
      "           2       0.63      0.63      0.63       211\n",
      "\n",
      "    accuracy                           0.67       480\n",
      "   macro avg       0.68      0.68      0.68       480\n",
      "weighted avg       0.67      0.67      0.67       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_tree = cross_val_predict(tree_clf,dataset,classes,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55       142\n",
      "           1       0.74      0.68      0.70       127\n",
      "           2       0.54      0.49      0.52       211\n",
      "\n",
      "    accuracy                           0.57       480\n",
      "   macro avg       0.59      0.59      0.59       480\n",
      "weighted avg       0.58      0.57      0.58       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(classes,resultados_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_edu.drop('Class',axis=1),df_edu['Class'],test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_random_forest(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1)\n",
    "    else: \n",
    "        rf = RandomForestClassifier(n_estimators=100,random_state=1, max_depth=maxdepth)\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_score = rf.score(X_train, y_train)*100\n",
    "    test_score = rf.score(X_test, y_test)*100\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (75.0, 61.80555555555556) \n",
      "3         (82.44047619047619, 68.05555555555556) \n",
      "4         (87.20238095238095, 71.52777777777779) \n",
      "10         (100.0, 75.69444444444444) \n",
      "15         (100.0, 79.86111111111111) \n",
      "Full         (100.0, 79.86111111111111) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_random_forest(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_random_forest(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_random_forest(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_random_forest(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_random_forest(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_random_forest(0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compara_modelos_decision_tree(maxdepth):\n",
    "    if maxdepth == 0:\n",
    "        df = DecisionTreeClassifier(random_state=1)\n",
    "    else: \n",
    "        df = DecisionTreeClassifier(random_state=1, max_depth=maxdepth)\n",
    "    df.fit(X_train, y_train)\n",
    "    train_score = df.score(X_train, y_train)*100\n",
    "    test_score = df.score(X_test, y_test)*100\n",
    "    return train_score,test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth      Training score       Testing score       \n",
      "-----      --------------       -------------       \n",
      "2         (63.988095238095234, 68.05555555555556) \n",
      "3         (73.21428571428571, 70.13888888888889) \n",
      "4         (79.16666666666666, 74.30555555555556) \n",
      "10         (99.10714285714286, 68.75) \n",
      "15         (100.0, 69.44444444444444) \n",
      "Full         (100.0, 69.44444444444444) \n"
     ]
    }
   ],
   "source": [
    "print('{:10} {:20} {:20}'.format('depth', 'Training score','Testing score'))\n",
    "print('{:10} {:20} {:20}'.format('-----', '--------------','-------------'))\n",
    "print('{:1}         {} '.format(2,str(compara_modelos_decision_tree(2))))\n",
    "print('{:1}         {} '.format(3,str(compara_modelos_decision_tree(3))))\n",
    "print('{:1}         {} '.format(4,str(compara_modelos_decision_tree(4))))\n",
    "print('{:1}         {} '.format(10,str(compara_modelos_decision_tree(10))))\n",
    "print('{:1}         {} '.format(15,str(compara_modelos_decision_tree(15))))\n",
    "print('{:1}         {} '.format('Full',str(compara_modelos_decision_tree(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunning do Modelo para Garantir o Melhor Desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como encontrar os melhores valores para os parametros do modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier(\n",
    "n_estimators=?,\n",
    "criterion='gini' ou 'entropy',\n",
    "max_depth=?,\n",
    "min_samples_split=?,\n",
    "min_samples_leaf=?\n",
    ") ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV para testes de Hyperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores de estimators ou quantidade de árvores da floresta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_estimators = [10, 20, 50, 100, 150]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para o critério de divisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_criterion = ['gini','entropy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para a profundidade máxima de cada árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_max_depth = [10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de possíveis valores para os parametros min_samples_split e min_samples_leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_min_samples_split = [2, 5, 10,15]\n",
    "valores_min_samples_leaf = [1, 5, 10,15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define um dicionário que recebe as listas de parâmetros e valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros_grid = dict(n_estimators=valores_estimators,\n",
    "                       criterion=valores_criterion,\n",
    "                       max_depth=valores_max_depth,\n",
    "                       min_samples_split=valores_min_samples_split,\n",
    "                       min_samples_leaf=valores_min_samples_leaf \n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicionário com os parametros que serão utilizados no grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 20, 50, 100, 150],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'max_depth': [10, 20, 50, 100],\n",
       " 'min_samples_split': [2, 5, 10, 15],\n",
       " 'min_samples_leaf': [1, 5, 10, 15]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametros_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instancia o GridSearch com o modelo a ser utilizado, parametros, número de folds e scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf, parametros_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplica o GridSearch passando as features e classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 50, 100],\n",
       "                         'min_samples_leaf': [1, 5, 10, 15],\n",
       "                         'min_samples_split': [2, 5, 10, 15],\n",
       "                         'n_estimators': [10, 20, 50, 100, 150]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(df_edu.drop('Class',axis=1),df_edu['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprime os scores por combinações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.01221099, 0.02302084, 0.05565062, 0.11050034, 0.16514997,\n",
       "        0.0120111 , 0.02282081, 0.05525041, 0.11190186, 0.16294789,\n",
       "        0.01221166, 0.02242026, 0.05404921, 0.10663853, 0.15861363,\n",
       "        0.01120429, 0.02202001, 0.05304832, 0.10459151, 0.16574521,\n",
       "        0.01161075, 0.0220202 , 0.05304809, 0.10469518, 0.15654216,\n",
       "        0.01161056, 0.02222323, 0.05304823, 0.10469489, 0.1567421 ,\n",
       "        0.0120111 , 0.02161956, 0.05304823, 0.10429435, 0.1550313 ,\n",
       "        0.01121011, 0.02141938, 0.05205302, 0.10283527, 0.15472255,\n",
       "        0.01201077, 0.02201996, 0.05204682, 0.100491  , 0.14991403,\n",
       "        0.01118374, 0.0212193 , 0.05102053, 0.10098243, 0.1498455 ,\n",
       "        0.01123538, 0.02117109, 0.0508153 , 0.10082121, 0.15217257,\n",
       "        0.01181064, 0.02121944, 0.0516468 , 0.10129209, 0.15093699,\n",
       "        0.01121001, 0.02101927, 0.05004554, 0.09929032, 0.14913578,\n",
       "        0.01101012, 0.02041869, 0.05004559, 0.09868946, 0.1467011 ,\n",
       "        0.01120429, 0.02081866, 0.0500433 , 0.09932671, 0.14793429,\n",
       "        0.01101012, 0.02038879, 0.05175247, 0.09800749, 0.14696765,\n",
       "        0.01235104, 0.02402911, 0.05623689, 0.11204896, 0.16561408,\n",
       "        0.01218362, 0.02317266, 0.05611401, 0.11130085, 0.16394892,\n",
       "        0.01181078, 0.02222013, 0.05404906, 0.10829849, 0.15894127,\n",
       "        0.01101017, 0.02182007, 0.05424905, 0.10769782, 0.15774307,\n",
       "        0.01181078, 0.02322145, 0.05585032, 0.10855217, 0.15693769,\n",
       "        0.01139574, 0.02142491, 0.05244536, 0.10429459, 0.15663128,\n",
       "        0.01201077, 0.02162132, 0.05216956, 0.10309372, 0.15313916,\n",
       "        0.01101165, 0.02121878, 0.05184722, 0.10169215, 0.15173783,\n",
       "        0.01101007, 0.02081885, 0.05024724, 0.09928985, 0.14873505,\n",
       "        0.01100974, 0.0210175 , 0.05064788, 0.09929008, 0.14953423,\n",
       "        0.01101017, 0.02081881, 0.05064631, 0.0992918 , 0.14853349,\n",
       "        0.01100988, 0.02101903, 0.05144677, 0.099891  , 0.14933414,\n",
       "        0.01080966, 0.02081914, 0.04964499, 0.09848962, 0.14633288,\n",
       "        0.01121016, 0.02061877, 0.04964495, 0.09828925, 0.14553204,\n",
       "        0.01100998, 0.0204186 , 0.04904613, 0.09648929, 0.14573226,\n",
       "        0.01080818, 0.02061911, 0.04944501, 0.09989061, 0.1483346 ,\n",
       "        0.01221142, 0.02322116, 0.05605087, 0.11130123, 0.16354856,\n",
       "        0.01181078, 0.02242036, 0.05424929, 0.10849867, 0.16094627,\n",
       "        0.01161065, 0.02181997, 0.05364857, 0.10509849, 0.15674071,\n",
       "        0.01100998, 0.02161808, 0.05244765, 0.10329723, 0.15454021,\n",
       "        0.01161051, 0.02162127, 0.05204406, 0.10289326, 0.15454202,\n",
       "        0.01180563, 0.02161794, 0.05204892, 0.10349255, 0.15373964,\n",
       "        0.01121039, 0.02142091, 0.05284634, 0.10409465, 0.15614171,\n",
       "        0.01201115, 0.02141948, 0.05264812, 0.10349402, 0.15113883,\n",
       "        0.01100998, 0.0210175 , 0.05124631, 0.10269313, 0.15193806,\n",
       "        0.01121025, 0.02121906, 0.05044575, 0.09948874, 0.14913568,\n",
       "        0.01100979, 0.02061887, 0.05084648, 0.10068974, 0.14993625,\n",
       "        0.01121054, 0.02121911, 0.0516469 , 0.10129185, 0.14833674,\n",
       "        0.01060972, 0.0204185 , 0.04904618, 0.09808908, 0.14593253,\n",
       "        0.01080956, 0.02021828, 0.04964514, 0.09688783, 0.14553232,\n",
       "        0.01101146, 0.02041864, 0.04924479, 0.09949059, 0.14493165,\n",
       "        0.01081166, 0.02041874, 0.04904637, 0.09708958, 0.14493003,\n",
       "        0.01181049, 0.02301946, 0.05545158, 0.10949783, 0.16334672,\n",
       "        0.01221132, 0.0230226 , 0.05444951, 0.10749588, 0.16014543,\n",
       "        0.01141028, 0.02201829, 0.05304823, 0.10489707, 0.15834217,\n",
       "        0.01181064, 0.02202001, 0.05304651, 0.10469499, 0.15434012,\n",
       "        0.01120839, 0.02141776, 0.05184698, 0.10329375, 0.15333924,\n",
       "        0.01121016, 0.0216197 , 0.0518487 , 0.10389276, 0.15353937,\n",
       "        0.0116107 , 0.02161975, 0.0522491 , 0.10389299, 0.15674186,\n",
       "        0.01181083, 0.02161965, 0.05224771, 0.10429454, 0.15554128,\n",
       "        0.01161079, 0.02141967, 0.05244751, 0.10289383, 0.151582  ,\n",
       "        0.01141038, 0.02140779, 0.05167913, 0.10084143, 0.15064411,\n",
       "        0.01100221, 0.02161961, 0.05105276, 0.1006916 , 0.14993625,\n",
       "        0.01181097, 0.02161956, 0.0526475 , 0.1036942 , 0.15474072,\n",
       "        0.01100969, 0.02101898, 0.05004539, 0.09848948, 0.14673309,\n",
       "        0.01101007, 0.02061872, 0.0500453 , 0.09842196, 0.14679856,\n",
       "        0.01121016, 0.02121911, 0.04964538, 0.09816489, 0.14880023,\n",
       "        0.01101165, 0.02163935, 0.05121961, 0.09901428, 0.157304  ,\n",
       "        0.01381235, 0.02522268, 0.05985436, 0.11990895, 0.1787622 ,\n",
       "        0.01281166, 0.02422199, 0.05845294, 0.11570501, 0.1721561 ,\n",
       "        0.0124114 , 0.02362161, 0.05704827, 0.11250219, 0.16766376,\n",
       "        0.01200328, 0.02312493, 0.05561714, 0.11001267, 0.16583991,\n",
       "        0.01181049, 0.02302098, 0.0549233 , 0.11062717, 0.16702051,\n",
       "        0.01259837, 0.02339993, 0.0565968 , 0.11121273, 0.16360154,\n",
       "        0.01201081, 0.02282057, 0.05505004, 0.10969963, 0.16334853,\n",
       "        0.01201081, 0.02262044, 0.05424924, 0.1082984 , 0.16034555,\n",
       "        0.01201081, 0.02302074, 0.05264773, 0.10489526, 0.15863156,\n",
       "        0.01171403, 0.02187729, 0.05295482, 0.10349402, 0.1562263 ,\n",
       "        0.01176834, 0.02160459, 0.05281243, 0.10457134, 0.15775723,\n",
       "        0.01196895, 0.02218094, 0.05238347, 0.10382209, 0.15558615,\n",
       "        0.01140394, 0.02120175, 0.0509829 , 0.1007946 , 0.15139732,\n",
       "        0.01098566, 0.02122817, 0.05117335, 0.10088573, 0.15073104,\n",
       "        0.01162825, 0.02162046, 0.05181432, 0.10102763, 0.15198951,\n",
       "        0.01140418, 0.02140412, 0.05121245, 0.10061917, 0.15080934,\n",
       "        0.01316872, 0.02479453, 0.06044865, 0.12415719, 0.18601351,\n",
       "        0.01317782, 0.02542858, 0.05917931, 0.11766081, 0.17662115,\n",
       "        0.01279035, 0.02420278, 0.06000323, 0.12621984, 0.17077265,\n",
       "        0.01221113, 0.02342095, 0.05645132, 0.11130104, 0.1665514 ,\n",
       "        0.01241112, 0.02302074, 0.05565042, 0.11150103, 0.16434951,\n",
       "        0.01241117, 0.02302089, 0.05545025, 0.10929961, 0.16268868,\n",
       "        0.01221099, 0.02242756, 0.05461206, 0.10848298, 0.16474948,\n",
       "        0.01201086, 0.02262049, 0.05457129, 0.10804133, 0.1622591 ,\n",
       "        0.01099648, 0.021805  , 0.05300841, 0.10463381, 0.15777411,\n",
       "        0.01198249, 0.02161922, 0.05264368, 0.10639315, 0.15680537,\n",
       "        0.01198263, 0.02200451, 0.05398593, 0.10494795, 0.15754266,\n",
       "        0.01181064, 0.02242007, 0.05364857, 0.10369415, 0.15634198,\n",
       "        0.0118104 , 0.02182026, 0.05184689, 0.10149212, 0.1515377 ,\n",
       "        0.01101046, 0.02121925, 0.05084615, 0.10159469, 0.15122919,\n",
       "        0.01161051, 0.02141929, 0.05124636, 0.10109196, 0.15218182,\n",
       "        0.01100178, 0.02163858, 0.05174327, 0.10229297, 0.15393929,\n",
       "        0.01301174, 0.02462244, 0.06025457, 0.12211084, 0.18116431,\n",
       "        0.01301193, 0.02442226, 0.05945401, 0.11670628, 0.17375765,\n",
       "        0.01257992, 0.0235652 , 0.05805278, 0.11316242, 0.16989026,\n",
       "        0.01281157, 0.02320275, 0.05635352, 0.11037097, 0.16442914,\n",
       "        0.01179938, 0.02297978, 0.05519934, 0.10847282, 0.16281271,\n",
       "        0.01219339, 0.0230516 , 0.05500789, 0.10883389, 0.16319094,\n",
       "        0.01198921, 0.02222905, 0.05480232, 0.10901194, 0.16298699,\n",
       "        0.01181383, 0.02222013, 0.05344858, 0.10609493, 0.15914464,\n",
       "        0.01141062, 0.02161975, 0.05264792, 0.10469513, 0.15674248,\n",
       "        0.01201096, 0.02201986, 0.05264764, 0.1036942 , 0.1552629 ,\n",
       "        0.01161065, 0.0220202 , 0.05265985, 0.10409431, 0.15484324,\n",
       "        0.01174197, 0.02205887, 0.05292368, 0.10348721, 0.15654898,\n",
       "        0.01097374, 0.02179189, 0.05118842, 0.10173173, 0.15173783,\n",
       "        0.01121006, 0.02101893, 0.05044603, 0.10069146, 0.15093679,\n",
       "        0.0112102 , 0.02121935, 0.05104666, 0.10149245, 0.16054554,\n",
       "        0.01181083, 0.02141953, 0.05124669, 0.10269337, 0.15184031,\n",
       "        0.01341505, 0.02542615, 0.06199713, 0.12355986, 0.17766724,\n",
       "        0.01301174, 0.02462234, 0.05926161, 0.11843476, 0.17589006,\n",
       "        0.01349134, 0.02342148, 0.05745192, 0.11350317, 0.16895361,\n",
       "        0.01221108, 0.02322135, 0.05605092, 0.11310272, 0.16675134,\n",
       "        0.01241136, 0.02282066, 0.05525017, 0.10909915, 0.1659842 ,\n",
       "        0.01261139, 0.02382154, 0.05744271, 0.11117463, 0.16411963,\n",
       "        0.01221166, 0.02299418, 0.05539846, 0.11074438, 0.16314816,\n",
       "        0.01221108, 0.02302113, 0.05484972, 0.10849857, 0.16094623,\n",
       "        0.01141043, 0.0220201 , 0.05324869, 0.10429487, 0.15894423,\n",
       "        0.01181073, 0.02202024, 0.054249  , 0.10445623, 0.15739822,\n",
       "        0.01161041, 0.02182002, 0.05324845, 0.10397592, 0.15586414,\n",
       "        0.01173368, 0.02187138, 0.05299959, 0.10682716, 0.15905328,\n",
       "        0.01158013, 0.02137756, 0.05184789, 0.10283427, 0.15222373,\n",
       "        0.01181078, 0.02140851, 0.05120354, 0.10140839, 0.15303059,\n",
       "        0.01141033, 0.02222033, 0.05124645, 0.10189252, 0.15073719,\n",
       "        0.01161046, 0.02141962, 0.05184698, 0.10149188, 0.1577436 ]),\n",
       " 'std_fit_time': array([4.00471698e-04, 6.32937496e-04, 4.90485433e-04, 8.00848028e-04,\n",
       "        2.09960252e-03, 5.09122765e-07, 4.00352677e-04, 4.00185624e-04,\n",
       "        4.62589474e-03, 1.60163641e-03, 4.00139105e-04, 4.90193437e-04,\n",
       "        6.32937457e-04, 5.69200829e-04, 6.19659077e-04, 3.88717856e-04,\n",
       "        3.23406696e-07, 1.78416128e-07, 6.42347681e-04, 1.86368193e-02,\n",
       "        4.90271273e-04, 2.43140197e-07, 3.81469727e-07, 4.90251785e-04,\n",
       "        4.90290718e-04, 4.90310261e-04, 3.98922776e-04, 6.32937496e-04,\n",
       "        4.90504874e-04, 4.90368655e-04, 2.33601546e-07, 8.00490399e-04,\n",
       "        4.67203091e-07, 4.00638694e-04, 6.69837065e-04, 4.00352506e-04,\n",
       "        4.90485433e-04, 1.14255994e-05, 4.30107926e-04, 3.91934491e-03,\n",
       "        4.10190833e-07, 1.90734863e-07, 6.32786740e-04, 4.90115546e-04,\n",
       "        7.39271682e-04, 3.90931361e-04, 3.59037970e-04, 1.02695891e-04,\n",
       "        8.36286342e-04, 6.65108403e-04, 3.94017922e-04, 4.31660456e-04,\n",
       "        3.54776408e-04, 1.66877745e-03, 2.21773457e-03, 4.00352506e-04,\n",
       "        4.00328675e-04, 4.90446468e-04, 7.49105612e-04, 4.00495600e-04,\n",
       "        4.00638609e-04, 3.50402318e-07, 4.62310777e-07, 4.00090427e-04,\n",
       "        2.09939795e-03, 6.33013000e-04, 4.90232417e-04, 5.76164530e-07,\n",
       "        4.90388074e-04, 1.01006522e-03, 2.67126772e-04, 4.00400176e-04,\n",
       "        6.29398866e-04, 3.56926408e-04, 7.48799855e-04, 2.78041453e-07,\n",
       "        5.17839169e-04, 7.49532328e-04, 5.85445353e-05, 5.82107230e-04,\n",
       "        4.27429099e-04, 4.38727051e-04, 2.54943278e-04, 8.29294173e-04,\n",
       "        1.34122302e-03, 4.07396435e-04, 3.14218227e-04, 6.34271133e-04,\n",
       "        1.16713627e-03, 7.48939962e-04, 4.00185681e-04, 4.00424014e-04,\n",
       "        1.09627984e-03, 4.00090399e-04, 7.52553567e-04, 3.01578299e-07,\n",
       "        4.00066404e-04, 1.72197008e-03, 8.00895705e-04, 3.72343177e-03,\n",
       "        4.00185709e-04, 7.49297007e-04, 1.16721009e-03, 2.71984571e-03,\n",
       "        1.60968765e-03, 4.82167266e-04, 4.86208397e-04, 4.98910583e-04,\n",
       "        7.49143886e-04, 1.88563887e-03, 2.78041453e-07, 4.91817797e-04,\n",
       "        4.71524614e-04, 6.35516708e-04, 5.27848181e-06, 3.19658771e-06,\n",
       "        4.00569268e-04, 7.49156597e-04, 4.90621721e-04, 4.87189721e-04,\n",
       "        3.87384339e-07, 4.00495543e-04, 3.99817291e-04, 3.96407191e-04,\n",
       "        4.90368586e-04, 1.78416128e-07, 6.33021530e-04, 4.91759658e-04,\n",
       "        4.00328647e-04, 1.20298405e-03, 2.61174468e-07, 3.99994889e-04,\n",
       "        4.90563478e-04, 3.99719965e-04, 4.88409583e-04, 5.12771799e-06,\n",
       "        4.98836396e-06, 4.90193413e-04, 7.49105718e-04, 3.97024892e-04,\n",
       "        4.00424156e-04, 4.00400318e-04, 8.00693044e-04, 8.00979139e-04,\n",
       "        9.82276984e-04, 7.49169335e-04, 4.90154518e-04, 8.00788503e-04,\n",
       "        1.16752890e-03, 7.96610593e-04, 2.78041453e-07, 4.90310214e-04,\n",
       "        5.96637433e-06, 4.89131682e-04, 4.90376714e-04, 3.99460874e-04,\n",
       "        4.90427224e-04, 4.90415707e-04, 7.48939932e-04, 1.16706274e-03,\n",
       "        4.00257139e-04, 4.00352478e-04, 1.90734863e-07, 1.94091348e-03,\n",
       "        4.90290811e-04, 4.00304837e-04, 4.90212843e-04, 4.00305064e-04,\n",
       "        8.00740781e-04, 7.48876311e-04, 4.90290742e-04, 4.00257139e-04,\n",
       "        4.90446491e-04, 6.35451721e-04, 4.92193763e-04, 9.53674316e-08,\n",
       "        4.88879710e-04, 8.00817232e-04, 3.98774072e-04, 1.01908736e-03,\n",
       "        4.90368586e-04, 4.88370635e-04, 3.91355219e-06, 4.00257139e-04,\n",
       "        1.85526213e-03, 4.02278168e-04, 4.88859664e-04, 3.22350383e-06,\n",
       "        4.88098313e-04, 4.90232324e-04, 3.99971150e-04, 4.88762074e-04,\n",
       "        3.99433870e-04, 8.95268687e-04, 1.41549357e-03, 2.43140197e-07,\n",
       "        4.90310237e-04, 4.90310261e-04, 1.02054365e-03, 3.19658771e-06,\n",
       "        9.53674316e-08, 3.21078222e-06, 4.00471783e-04, 2.24681981e-03,\n",
       "        1.16758603e-03, 4.00400403e-04, 4.00400290e-04, 4.90212913e-04,\n",
       "        4.88525591e-04, 6.32937532e-04, 1.90734863e-07, 4.90621652e-04,\n",
       "        7.49258562e-04, 1.02323942e-03, 1.46878300e-03, 4.00138196e-04,\n",
       "        4.00495657e-04, 4.90329667e-04, 7.48914608e-04, 9.78774594e-04,\n",
       "        4.90446468e-04, 4.90290788e-04, 3.38722241e-06, 1.09610572e-03,\n",
       "        4.00384366e-04, 4.00257139e-04, 4.00266171e-04, 8.00764587e-04,\n",
       "        3.96534725e-04, 4.87017239e-04, 3.05548083e-06, 4.90271273e-04,\n",
       "        4.00352506e-04, 4.90504874e-04, 1.16725892e-03, 4.01198997e-04,\n",
       "        4.90290765e-04, 6.22194841e-06, 5.91816196e-06, 4.03745785e-04,\n",
       "        4.00280992e-04, 6.33171028e-04, 4.89249294e-04, 4.91799669e-04,\n",
       "        1.32580086e-03, 4.00424014e-04, 3.12828435e-06, 4.93537778e-04,\n",
       "        4.88447756e-04, 6.27886029e-04, 4.87036123e-04, 3.38722241e-06,\n",
       "        5.05447388e-06, 4.01329121e-04, 2.40085318e-03, 4.00352506e-04,\n",
       "        1.90734863e-07, 3.36972422e-06, 8.00561926e-04, 7.42574552e-04,\n",
       "        4.01343517e-04, 4.91720702e-04, 4.00424043e-04, 1.47102787e-03,\n",
       "        4.00288069e-04, 4.00328647e-04, 4.90319169e-04, 4.01207209e-04,\n",
       "        9.81949122e-04, 4.87015698e-04, 4.90232324e-04, 4.90134984e-04,\n",
       "        3.99683461e-04, 1.16573578e-03, 1.02053426e-03, 4.00328647e-04,\n",
       "        4.90446491e-04, 7.49041914e-04, 7.48710553e-04, 1.85663060e-03,\n",
       "        4.90407565e-04, 4.90349171e-04, 1.35754884e-03, 1.16752881e-03,\n",
       "        1.84871443e-03, 4.90446491e-04, 4.76546184e-04, 9.17993245e-04,\n",
       "        4.12700194e-04, 8.86819170e-04, 3.28494084e-05, 4.90310237e-04,\n",
       "        4.67450410e-04, 4.90602210e-04, 7.49105703e-04, 1.16715260e-03,\n",
       "        4.90465925e-04, 4.90193483e-04, 4.90173964e-04, 2.06088502e-03,\n",
       "        2.61174468e-07, 3.98950589e-07, 1.90734863e-07, 4.90310214e-04,\n",
       "        4.90602210e-04, 1.90734863e-07, 4.90310330e-04, 2.78041453e-07,\n",
       "        4.21344996e-04, 5.99150726e-04, 4.00328789e-04, 4.00376643e-04,\n",
       "        4.90135030e-04, 1.24187713e-04, 1.68326375e-03, 6.23258624e-04,\n",
       "        4.63551695e-04, 3.98992095e-04, 1.26784059e-03, 2.90114308e-03,\n",
       "        4.00328988e-04, 4.00471897e-04, 4.00471698e-04, 2.31735581e-03,\n",
       "        2.24715116e-03, 4.00543326e-04, 4.00376359e-04, 4.90290718e-04,\n",
       "        4.90660616e-04, 6.33088257e-04, 8.00705013e-04, 4.90018253e-04,\n",
       "        6.77612279e-06, 4.90290742e-04, 6.09441791e-04, 2.65374337e-05,\n",
       "        2.00595310e-04, 5.19631100e-04, 7.59985690e-05, 1.86548336e-03,\n",
       "        4.00400233e-04, 1.50789149e-07, 1.73443445e-04, 1.33032757e-03,\n",
       "        8.93086025e-04, 4.80175980e-04, 4.81997548e-04, 5.10945832e-04,\n",
       "        1.58502825e-03, 2.24578915e-03, 2.13248060e-07, 4.00471755e-04,\n",
       "        2.86102295e-07, 8.00442729e-04, 4.00495543e-04, 2.61174468e-07,\n",
       "        4.90173964e-04, 4.00328675e-04, 2.48443308e-03, 4.00543298e-04,\n",
       "        1.50789149e-07, 2.61007033e-03, 4.90388120e-04, 1.16706267e-03,\n",
       "        3.69855869e-03, 6.05189530e-04, 4.43181700e-04, 4.98584307e-04,\n",
       "        4.90193437e-04, 1.49713414e-03, 3.90220847e-04, 4.89873669e-04,\n",
       "        3.99625175e-04, 4.51583243e-04, 1.93939035e-03, 1.20870046e-04,\n",
       "        3.76216075e-04, 5.13418042e-04, 7.02935519e-04, 1.87668606e-03,\n",
       "        5.05177669e-04, 4.00336434e-04, 4.76033965e-05, 3.02356851e-04,\n",
       "        1.46009225e-03, 6.60565598e-05, 3.34373590e-04, 3.87267331e-04,\n",
       "        1.08343489e-03, 1.40995741e-03, 4.69204241e-04, 4.91989142e-04,\n",
       "        7.65035522e-04, 6.51581183e-05, 1.95563235e-03, 4.95223491e-04,\n",
       "        4.68658391e-04, 3.97033202e-04, 5.26877325e-04, 1.60066018e-03,\n",
       "        4.22086669e-04, 4.05874014e-04, 4.27142225e-04, 2.07507147e-03,\n",
       "        8.04361489e-03, 4.20295464e-04, 1.46710903e-03, 6.29554667e-04,\n",
       "        2.30192896e-03, 1.63558099e-03, 3.91957957e-04, 4.03566711e-04,\n",
       "        3.65459221e-03, 3.30583098e-03, 1.26150603e-03, 4.00161772e-04,\n",
       "        4.89959789e-04, 4.90076589e-04, 4.00376473e-04, 8.00645434e-04,\n",
       "        4.90076636e-04, 1.50789149e-07, 1.20141513e-03, 1.35759102e-03,\n",
       "        1.94077585e-03, 4.90427015e-04, 1.16800773e-07, 8.00466573e-04,\n",
       "        1.60182121e-03, 4.54962160e-04, 4.00471726e-04, 4.99139713e-04,\n",
       "        5.14170140e-04, 4.85132672e-04, 2.73000851e-03, 2.78041453e-07,\n",
       "        4.90212913e-04, 5.82650182e-04, 6.61171131e-05, 1.94171053e-03,\n",
       "        7.12000433e-05, 3.61105679e-04, 5.38105187e-05, 5.23595492e-04,\n",
       "        2.68147862e-03, 7.37169890e-05, 4.67468874e-04, 4.91215288e-04,\n",
       "        1.23471031e-03, 1.30861460e-03, 6.16619578e-04, 6.14929070e-04,\n",
       "        5.79804664e-04, 1.43525237e-03, 1.62623368e-03, 4.00233279e-04,\n",
       "        4.90641283e-04, 8.00657294e-04, 1.74484986e-03, 1.94072657e-03,\n",
       "        4.00352677e-04, 4.00400318e-04, 7.49131217e-04, 4.90018206e-04,\n",
       "        4.90524389e-04, 4.86280395e-07, 4.00304865e-04, 4.00447902e-04,\n",
       "        1.48824847e-03, 6.57574198e-04, 4.90660663e-04, 4.90076682e-04,\n",
       "        4.00328675e-04, 6.33239057e-04, 2.13313892e-03, 1.00400711e-04,\n",
       "        5.72030307e-04, 5.34495872e-04, 1.16712808e-03, 2.31778021e-03,\n",
       "        3.16297988e-07, 4.90563269e-04, 1.16699725e-03, 1.09688927e-03,\n",
       "        8.94895521e-04, 3.37174788e-07, 4.90290742e-04, 4.90232324e-04,\n",
       "        8.01038820e-04, 1.20082697e-03, 5.45215469e-04, 4.55988796e-04,\n",
       "        6.33088329e-04, 7.18290576e-04, 1.83198321e-03, 4.00257309e-04,\n",
       "        4.11050795e-04, 4.40676262e-04, 3.88252884e-04, 8.17151616e-04,\n",
       "        3.81339033e-04, 4.48638646e-05, 7.23136975e-04, 4.94083951e-04,\n",
       "        2.22521209e-03, 3.92784096e-04, 1.50094341e-04, 6.23708734e-04,\n",
       "        7.52154968e-04, 2.00031334e-03, 6.36290646e-04, 4.74178259e-04,\n",
       "        7.47808767e-04, 9.03177328e-04, 1.45150842e-03, 4.01875075e-04,\n",
       "        4.00304837e-04, 4.87056482e-04, 8.93619330e-04, 8.95428642e-04,\n",
       "        4.90154472e-04, 4.90232370e-04, 4.90349217e-04, 1.02031926e-03,\n",
       "        1.96106552e-03, 3.23406696e-07, 2.61174468e-07, 4.90505013e-04,\n",
       "        8.00609688e-04, 1.61074999e-03, 4.90388050e-04, 1.90734863e-07,\n",
       "        8.00268710e-04, 1.55074322e-03, 3.91108267e-04, 3.71892835e-04,\n",
       "        5.45143747e-04, 5.96202696e-04, 7.80819345e-04, 2.45066927e-03,\n",
       "        5.21729149e-05, 7.43574204e-04, 1.03133201e-03, 5.61964201e-04,\n",
       "        1.35775276e-03, 4.00495600e-04, 2.78041453e-07, 4.90271273e-04,\n",
       "        4.90193413e-04, 1.16731619e-03, 4.00185652e-04, 4.00495941e-04,\n",
       "        4.62310777e-07, 1.85617814e-03, 2.03222335e-02, 4.00806051e-04,\n",
       "        4.90563292e-04, 4.00162510e-04, 1.35761917e-03, 6.03694742e-04,\n",
       "        4.94329113e-04, 4.94190474e-04, 6.65956313e-05, 3.66545526e-03,\n",
       "        1.34303653e-03, 5.09122765e-07, 4.90290788e-04, 4.19723362e-04,\n",
       "        2.49812164e-03, 2.14772126e-03, 1.00234573e-03, 4.90213029e-04,\n",
       "        4.89629281e-04, 4.90310353e-04, 7.48888969e-04, 4.00424156e-04,\n",
       "        4.00376444e-04, 1.90734863e-07, 3.58070151e-03, 4.90524366e-04,\n",
       "        4.90368794e-04, 4.00280963e-04, 4.00781646e-04, 6.33239046e-04,\n",
       "        1.58716803e-03, 4.90465972e-04, 4.00400233e-04, 4.72329227e-04,\n",
       "        2.14152162e-03, 6.35752851e-04, 4.00138338e-04, 3.66394672e-05,\n",
       "        5.05874943e-04, 1.95770422e-03, 1.09649758e-03, 4.00185652e-04,\n",
       "        3.87384339e-07, 4.00352592e-04, 4.90465925e-04, 7.48863483e-04,\n",
       "        4.90115523e-04, 2.13248060e-07, 4.00161828e-04, 9.80669073e-04,\n",
       "        3.54741458e-03, 4.00639006e-04, 6.33012860e-04, 1.16688280e-03,\n",
       "        3.70865212e-04, 1.31239815e-03, 4.90388120e-04, 4.00280992e-04,\n",
       "        4.00161885e-04, 6.68322917e-04, 7.74434260e-04, 4.25257445e-04,\n",
       "        3.12657161e-04, 6.19481625e-04, 1.50635113e-03, 1.01715001e-03,\n",
       "        4.73518088e-04, 3.75821619e-04, 3.10149066e-04, 1.69567470e-03,\n",
       "        1.18178802e-03, 4.00305093e-04, 4.91095661e-04, 3.62463255e-04,\n",
       "        7.59201229e-04, 3.58462887e-03, 4.90777440e-04, 7.48787084e-04,\n",
       "        4.00400176e-04, 7.49296946e-04, 1.35806908e-03, 4.90135077e-04,\n",
       "        4.90388189e-04, 4.00424185e-04, 8.01050710e-04, 7.81983864e-03]),\n",
       " 'mean_score_time': array([0.0012012 , 0.00200195, 0.0038033 , 0.00660605, 0.00920839,\n",
       "        0.001401  , 0.00160141, 0.00380335, 0.00660582, 0.00960851,\n",
       "        0.00120063, 0.00180168, 0.00360327, 0.00676298, 0.00961967,\n",
       "        0.00119781, 0.00160131, 0.00360312, 0.00641832, 0.00898838,\n",
       "        0.00140104, 0.00200181, 0.00400367, 0.00660596, 0.00900807,\n",
       "        0.00120115, 0.00159836, 0.003403  , 0.00600572, 0.00920849,\n",
       "        0.00100074, 0.00180159, 0.00400362, 0.00660639, 0.00920882,\n",
       "        0.00100093, 0.00200171, 0.00380349, 0.00639453, 0.00921264,\n",
       "        0.00140133, 0.00200191, 0.0032032 , 0.00640602, 0.00922871,\n",
       "        0.00100107, 0.0019824 , 0.003406  , 0.00622854, 0.00913329,\n",
       "        0.00100141, 0.00183187, 0.00340166, 0.00680647, 0.00917025,\n",
       "        0.00120115, 0.00200171, 0.00340323, 0.00620551, 0.00920854,\n",
       "        0.00100098, 0.00180149, 0.00320287, 0.00620561, 0.00900784,\n",
       "        0.00120091, 0.00180159, 0.00320272, 0.0062057 , 0.00898123,\n",
       "        0.00100031, 0.00180178, 0.00340309, 0.00623484, 0.00900784,\n",
       "        0.00120101, 0.00200167, 0.0036006 , 0.00640273, 0.00904794,\n",
       "        0.00097823, 0.00199594, 0.00380015, 0.00638623, 0.01000471,\n",
       "        0.00157552, 0.00200195, 0.00362096, 0.00720663, 0.00980887,\n",
       "        0.00120111, 0.00200186, 0.00360322, 0.00660577, 0.00921149,\n",
       "        0.00200181, 0.00160127, 0.00340328, 0.00680609, 0.00980916,\n",
       "        0.00120106, 0.00200176, 0.00340343, 0.00680614, 0.00920858,\n",
       "        0.00160666, 0.00162473, 0.00340319, 0.00640588, 0.00920725,\n",
       "        0.00100093, 0.00159993, 0.00388284, 0.00620546, 0.00900822,\n",
       "        0.00099936, 0.00160203, 0.00360155, 0.00640588, 0.00900807,\n",
       "        0.00140114, 0.00160155, 0.00360184, 0.00660553, 0.00900817,\n",
       "        0.00100284, 0.00200186, 0.00340285, 0.0062057 , 0.00900807,\n",
       "        0.0010006 , 0.00180178, 0.00340285, 0.00620399, 0.00880952,\n",
       "        0.00100098, 0.00160141, 0.0038033 , 0.00620723, 0.00900645,\n",
       "        0.0016016 , 0.00200162, 0.00340304, 0.00620556, 0.00940852,\n",
       "        0.00120096, 0.00180163, 0.00320301, 0.00620565, 0.00880804,\n",
       "        0.00100083, 0.00180163, 0.00360155, 0.00640574, 0.00860791,\n",
       "        0.00120277, 0.00180125, 0.00320301, 0.0066061 , 0.00900812,\n",
       "        0.00120072, 0.00140095, 0.00400357, 0.00680599, 0.00920835,\n",
       "        0.00140133, 0.00180168, 0.00320282, 0.00640578, 0.00980878,\n",
       "        0.00140128, 0.00200181, 0.00340319, 0.00660453, 0.00921011,\n",
       "        0.00140133, 0.00180316, 0.00400186, 0.00600553, 0.00900826,\n",
       "        0.00120111, 0.00160151, 0.00380511, 0.0062057 , 0.00900812,\n",
       "        0.00100589, 0.00160141, 0.00380349, 0.00620542, 0.00920844,\n",
       "        0.00120106, 0.00200191, 0.00340314, 0.00680623, 0.0096087 ,\n",
       "        0.00100064, 0.00180159, 0.00380325, 0.00620551, 0.00900831,\n",
       "        0.00100088, 0.00160151, 0.00380363, 0.00640602, 0.00880804,\n",
       "        0.0012013 , 0.00180163, 0.00340328, 0.00600705, 0.00900803,\n",
       "        0.00120115, 0.00160141, 0.0034029 , 0.00620718, 0.00900826,\n",
       "        0.00140114, 0.00180168, 0.00340323, 0.00640583, 0.0092083 ,\n",
       "        0.00120106, 0.00160308, 0.00319958, 0.00620575, 0.00900822,\n",
       "        0.00120144, 0.00160151, 0.00300274, 0.006004  , 0.0088079 ,\n",
       "        0.00139866, 0.00180159, 0.00340314, 0.00640554, 0.00900793,\n",
       "        0.00120087, 0.00199995, 0.00340142, 0.00620584, 0.00900817,\n",
       "        0.00140152, 0.00180321, 0.00340343, 0.00640755, 0.00940852,\n",
       "        0.00120091, 0.00140142, 0.00360327, 0.00620732, 0.00920844,\n",
       "        0.00160317, 0.00160151, 0.00400357, 0.00620556, 0.00941038,\n",
       "        0.00120115, 0.00180178, 0.00360494, 0.00640602, 0.00920997,\n",
       "        0.00120111, 0.00200195, 0.00360336, 0.0064075 , 0.00900822,\n",
       "        0.00120106, 0.00160151, 0.00340314, 0.00640564, 0.00921011,\n",
       "        0.00099916, 0.00160155, 0.00340133, 0.0062058 , 0.00900846,\n",
       "        0.00100083, 0.00160122, 0.00360312, 0.0062058 , 0.00900826,\n",
       "        0.00120096, 0.00180135, 0.0038034 , 0.00660582, 0.00940862,\n",
       "        0.00100083, 0.00160155, 0.00360312, 0.00661654, 0.00940866,\n",
       "        0.00140162, 0.00160165, 0.00340166, 0.00620551, 0.00880785,\n",
       "        0.00120087, 0.00180182, 0.00400391, 0.00620556, 0.00900822,\n",
       "        0.00100112, 0.00140152, 0.00340319, 0.00600533, 0.00880799,\n",
       "        0.00100079, 0.00180149, 0.00340328, 0.00620565, 0.00900812,\n",
       "        0.00100107, 0.00200181, 0.00380311, 0.0064188 , 0.00900698,\n",
       "        0.00119982, 0.001999  , 0.00378256, 0.00640092, 0.00960898,\n",
       "        0.00140123, 0.00200205, 0.00360336, 0.00680618, 0.00980878,\n",
       "        0.0012012 , 0.00160141, 0.00320282, 0.00640588, 0.00940862,\n",
       "        0.00140123, 0.00180163, 0.00340309, 0.00660601, 0.00980873,\n",
       "        0.00100021, 0.00168786, 0.00340319, 0.00620584, 0.00957565,\n",
       "        0.00120091, 0.00180168, 0.00341721, 0.0066    , 0.00960321,\n",
       "        0.00140138, 0.00200038, 0.00380244, 0.00640898, 0.00920453,\n",
       "        0.00100069, 0.00200195, 0.0038034 , 0.00640583, 0.00940847,\n",
       "        0.00140147, 0.00160146, 0.00380344, 0.00640588, 0.00920849,\n",
       "        0.00100093, 0.00200195, 0.00360341, 0.00700626, 0.00940847,\n",
       "        0.00119834, 0.00199995, 0.00340295, 0.00620565, 0.00917592,\n",
       "        0.00103211, 0.0020009 , 0.00359263, 0.0060216 , 0.0092793 ,\n",
       "        0.00140104, 0.00205622, 0.00379891, 0.00657482, 0.00926771,\n",
       "        0.00119734, 0.00180154, 0.00362177, 0.00601721, 0.00901403,\n",
       "        0.00119925, 0.00140128, 0.00358028, 0.00640564, 0.00923796,\n",
       "        0.00100117, 0.00200186, 0.00360327, 0.00597363, 0.00902362,\n",
       "        0.0012012 , 0.00179572, 0.00319958, 0.00620456, 0.00879006,\n",
       "        0.00120072, 0.00180154, 0.00399618, 0.00685716, 0.00980697,\n",
       "        0.00179629, 0.00220175, 0.00360222, 0.00677953, 0.00959749,\n",
       "        0.00140891, 0.00180149, 0.0035996 , 0.00700674, 0.00940609,\n",
       "        0.00140123, 0.00180192, 0.00340319, 0.00660615, 0.00940838,\n",
       "        0.00100102, 0.0016016 , 0.00380373, 0.00640578, 0.00940838,\n",
       "        0.00120106, 0.00200186, 0.00340314, 0.00680609, 0.00930543,\n",
       "        0.00120111, 0.00200171, 0.0036077 , 0.00640831, 0.00960884,\n",
       "        0.00100064, 0.00200176, 0.00336075, 0.00620255, 0.00914016,\n",
       "        0.00120034, 0.00180068, 0.00379505, 0.00619802, 0.00904479,\n",
       "        0.00100093, 0.00179915, 0.00316544, 0.00682011, 0.00921087,\n",
       "        0.00119982, 0.00201755, 0.00360198, 0.00640888, 0.00940895,\n",
       "        0.0016016 , 0.00200191, 0.00380354, 0.00640564, 0.00920863,\n",
       "        0.00100126, 0.00200138, 0.00360351, 0.00640583, 0.00920835,\n",
       "        0.0014008 , 0.00180168, 0.00340309, 0.00620589, 0.00917335,\n",
       "        0.00120101, 0.0020021 , 0.00360336, 0.00620546, 0.00918283,\n",
       "        0.00156775, 0.00199838, 0.00380359, 0.00600734, 0.00900831,\n",
       "        0.0012012 , 0.0018014 , 0.0036036 , 0.00640574, 0.00980902,\n",
       "        0.00140114, 0.00180154, 0.00340304, 0.00640569, 0.00940881,\n",
       "        0.00119748, 0.00180192, 0.00340309, 0.00643983, 0.00940866,\n",
       "        0.0012012 , 0.00180178, 0.00340295, 0.00620379, 0.00901351,\n",
       "        0.00120091, 0.00180149, 0.00360351, 0.00636306, 0.00940557,\n",
       "        0.00156164, 0.00199728, 0.0033968 , 0.00678101, 0.00921745,\n",
       "        0.00119805, 0.00180144, 0.00360136, 0.00620408, 0.00960875,\n",
       "        0.00119801, 0.00160141, 0.00340309, 0.00620575, 0.00900812,\n",
       "        0.001401  , 0.00160155, 0.00340271, 0.00620556, 0.00920825,\n",
       "        0.00100093, 0.00200205, 0.00360322, 0.00640588, 0.00900807,\n",
       "        0.00100074, 0.00180144, 0.00340328, 0.00600562, 0.00900807,\n",
       "        0.00100079, 0.00200143, 0.00344429, 0.00656047, 0.00966907,\n",
       "        0.00120106, 0.00201888, 0.00340333, 0.00677199, 0.00900812,\n",
       "        0.00120134, 0.00180178, 0.00360317, 0.0062057 , 0.00900841,\n",
       "        0.00100098, 0.00160117, 0.00320258, 0.00640554, 0.00900836,\n",
       "        0.00120101, 0.00200171, 0.0038033 , 0.00620546, 0.00940871,\n",
       "        0.00120134, 0.00200906, 0.00400348, 0.00680614, 0.00940881,\n",
       "        0.00140128, 0.00200176, 0.00368681, 0.00677624, 0.00934672,\n",
       "        0.00120091, 0.00180182, 0.00360317, 0.00620542, 0.00900826,\n",
       "        0.00180163, 0.00200167, 0.00340338, 0.00680614, 0.00960889,\n",
       "        0.00120106, 0.00180168, 0.0038034 , 0.00620556, 0.00965667,\n",
       "        0.0016017 , 0.00180168, 0.00400367, 0.00660605, 0.00920835,\n",
       "        0.00140109, 0.00200186, 0.0032032 , 0.00692387, 0.00940857,\n",
       "        0.0012012 , 0.00140109, 0.00400367, 0.00640583, 0.00900826,\n",
       "        0.00160131, 0.0018014 , 0.00340276, 0.00640593, 0.00940852,\n",
       "        0.00120091, 0.00200162, 0.00340323, 0.00680604, 0.00920844,\n",
       "        0.00140142, 0.00200162, 0.0038033 , 0.00638566, 0.0095521 ,\n",
       "        0.00120096, 0.00200014, 0.00360527, 0.00658407, 0.00994339,\n",
       "        0.00122614, 0.0018003 , 0.00380349, 0.00617943, 0.00900655,\n",
       "        0.00097642, 0.00180006, 0.00380521, 0.00601649, 0.00919318,\n",
       "        0.00160136, 0.00200162, 0.00360332, 0.00620561, 0.00920815,\n",
       "        0.00160141, 0.00200148, 0.00380349, 0.00660629, 0.00980868]),\n",
       " 'std_score_time': array([4.00638637e-04, 2.33601546e-07, 4.00209555e-04, 4.90426992e-04,\n",
       "        4.00209469e-04, 4.90524366e-04, 4.90621745e-04, 4.00352506e-04,\n",
       "        4.90329691e-04, 4.90271319e-04, 4.00568229e-04, 4.00042601e-04,\n",
       "        4.90310214e-04, 5.18662114e-04, 4.74388569e-04, 4.01900297e-04,\n",
       "        4.90154472e-04, 4.90290765e-04, 4.80544309e-04, 3.98160455e-05,\n",
       "        4.90290742e-04, 4.37028474e-07, 3.23406696e-07, 4.90251878e-04,\n",
       "        1.16800773e-07, 4.00424043e-04, 4.87774930e-04, 4.90232370e-04,\n",
       "        2.78041453e-07, 4.00400176e-04, 3.23406696e-07, 4.00233279e-04,\n",
       "        3.87384339e-07, 4.90212959e-04, 4.00353444e-04, 9.53674316e-08,\n",
       "        2.33601546e-07, 4.00781702e-04, 4.76573623e-04, 3.98410775e-04,\n",
       "        4.90446746e-04, 2.43140197e-07, 4.00400290e-04, 4.90407542e-04,\n",
       "        3.79987250e-04, 1.78416128e-07, 3.88387890e-05, 4.87042169e-04,\n",
       "        3.91533357e-04, 4.45871923e-04, 3.50402318e-07, 4.17454377e-04,\n",
       "        4.91720702e-04, 4.00471783e-04, 4.21622193e-04, 4.00304865e-04,\n",
       "        2.78041453e-07, 4.90427084e-04, 4.00328647e-04, 4.00257111e-04,\n",
       "        3.87384339e-07, 4.00424043e-04, 4.00209697e-04, 4.00519609e-04,\n",
       "        2.43140197e-07, 4.00424128e-04, 4.00591081e-04, 4.00042886e-04,\n",
       "        4.00233308e-04, 5.37641033e-05, 1.38693233e-06, 4.00567065e-04,\n",
       "        4.90251854e-04, 3.89942443e-04, 2.43140197e-07, 4.00376359e-04,\n",
       "        2.43140197e-07, 4.87943272e-04, 4.92639320e-04, 7.35851667e-05,\n",
       "        4.47043419e-05, 1.17543986e-05, 3.99247669e-04, 5.07629816e-04,\n",
       "        1.03238317e-04, 4.71414329e-04, 3.16297988e-07, 5.06600661e-04,\n",
       "        9.80406250e-04, 4.00352506e-04, 4.00209498e-04, 1.16800773e-07,\n",
       "        4.90368655e-04, 4.90388120e-04, 3.98827449e-04, 9.53674316e-08,\n",
       "        4.90310376e-04, 4.90290765e-04, 4.00519410e-04, 4.00376387e-04,\n",
       "        4.00233336e-04, 5.00111031e-07, 4.90076682e-04, 4.00304809e-04,\n",
       "        4.00352506e-04, 4.94606072e-04, 4.63126371e-04, 4.90271273e-04,\n",
       "        4.90426992e-04, 4.00909444e-04, 1.78416128e-07, 4.89130172e-04,\n",
       "        4.70736613e-04, 4.00352506e-04, 3.16297988e-07, 3.29535533e-06,\n",
       "        4.90759580e-04, 4.89113283e-04, 4.90427061e-04, 3.56832255e-07,\n",
       "        4.90212867e-04, 4.90349148e-04, 4.88762120e-04, 4.91168072e-04,\n",
       "        1.50789149e-07, 3.31530443e-06, 1.16800773e-07, 4.90446630e-04,\n",
       "        4.00471698e-04, 2.43140197e-07, 1.78416128e-07, 4.00447931e-04,\n",
       "        4.90544024e-04, 4.01222629e-04, 4.01245291e-04, 4.97741255e-06,\n",
       "        4.90329667e-04, 4.00209697e-04, 3.99600577e-04, 3.45961707e-06,\n",
       "        4.90290811e-04, 3.87384339e-07, 4.90485409e-04, 4.00304837e-04,\n",
       "        8.00839630e-04, 4.00519382e-04, 4.00257139e-04, 4.00495770e-04,\n",
       "        4.00257111e-04, 4.00376359e-04, 2.78041453e-07, 4.00376416e-04,\n",
       "        4.89209362e-04, 4.90349148e-04, 4.90407542e-04, 3.99508030e-04,\n",
       "        4.00185937e-04, 4.00376359e-04, 4.90173918e-04, 9.53674316e-08,\n",
       "        4.00281048e-04, 4.90563292e-04, 1.78416128e-07, 4.00590968e-04,\n",
       "        4.00471783e-04, 4.90446468e-04, 4.00280992e-04, 3.99994889e-04,\n",
       "        4.90310214e-04, 4.00424043e-04, 4.90290718e-04, 2.33601546e-07,\n",
       "        4.90368586e-04, 4.92497551e-04, 4.03881101e-04, 4.90251785e-04,\n",
       "        4.01272790e-04, 3.45830238e-06, 0.00000000e+00, 1.16800773e-07,\n",
       "        4.00328647e-04, 4.90310191e-04, 4.01246198e-04, 4.00471698e-04,\n",
       "        9.53674316e-08, 4.18965962e-06, 4.90329644e-04, 4.00304837e-04,\n",
       "        3.95741680e-04, 4.00543326e-04, 4.00114187e-04, 1.90734863e-07,\n",
       "        4.90310214e-04, 4.00471812e-04, 4.90427084e-04, 1.50789149e-07,\n",
       "        4.00590968e-04, 4.00424071e-04, 4.00328732e-04, 1.16800773e-07,\n",
       "        1.50789149e-07, 4.90407589e-04, 4.00495657e-04, 4.90310214e-04,\n",
       "        4.00257111e-04, 4.00352563e-04, 4.00614834e-04, 4.90388074e-04,\n",
       "        3.42062119e-06, 3.23406696e-07, 4.00304837e-04, 4.90427084e-04,\n",
       "        4.90310191e-04, 3.99268125e-04, 1.90734863e-07, 4.90212936e-04,\n",
       "        4.00400659e-04, 4.90524343e-04, 4.90174010e-04, 4.00376331e-04,\n",
       "        4.00352506e-04, 4.91603903e-04, 4.02110785e-04, 4.00805569e-04,\n",
       "        2.78041453e-07, 4.00280963e-04, 4.90407519e-04, 2.43140197e-07,\n",
       "        3.17231128e-06, 4.00304809e-04, 4.89425125e-04, 7.48927196e-04,\n",
       "        4.90407542e-04, 4.90407565e-04, 1.50789149e-07, 4.00328647e-04,\n",
       "        3.04056140e-06, 4.91623633e-04, 4.00638580e-04, 2.13248060e-07,\n",
       "        4.90388074e-04, 4.00938549e-04, 4.90466018e-04, 4.88879686e-04,\n",
       "        4.90426992e-04, 4.00543270e-04, 4.90076613e-04, 4.90310191e-04,\n",
       "        3.99555185e-04, 4.00304837e-04, 4.88371473e-04, 4.90310191e-04,\n",
       "        9.53674316e-08, 4.00424043e-04, 4.89014953e-04, 4.00304809e-04,\n",
       "        4.00328675e-04, 4.88273716e-04, 4.90504921e-04, 3.99674672e-04,\n",
       "        4.04634089e-04, 9.53674316e-08, 4.90388213e-04, 4.92516627e-04,\n",
       "        9.53674316e-08, 4.00471698e-04, 4.90115546e-04, 4.90407542e-04,\n",
       "        4.90621675e-04, 3.99601402e-04, 3.31873181e-06, 4.90154472e-04,\n",
       "        4.88223560e-04, 4.00185681e-04, 4.10190833e-07, 2.78041453e-07,\n",
       "        4.90563269e-04, 4.90388050e-04, 4.00543241e-04, 3.56832255e-07,\n",
       "        4.00280992e-04, 7.48608592e-04, 4.00376359e-04, 4.90135216e-04,\n",
       "        8.00418939e-04, 9.53674316e-08, 4.90349171e-04, 4.90485525e-04,\n",
       "        4.77375404e-04, 4.90699620e-04, 4.90212936e-04, 4.90524552e-04,\n",
       "        4.91133352e-04, 4.00209469e-04, 4.00400233e-04, 4.00328704e-04,\n",
       "        4.00471840e-04, 4.15696997e-07, 4.00424241e-04, 3.81469727e-07,\n",
       "        2.13248060e-07, 4.90388120e-04, 4.90271273e-04, 2.33601546e-07,\n",
       "        4.00352563e-04, 3.23406696e-07, 4.00662490e-04, 4.90388074e-04,\n",
       "        4.00734033e-04, 1.78416128e-07, 2.78041453e-07, 4.10190833e-07,\n",
       "        4.00352563e-04, 4.77570794e-04, 2.15369983e-06, 4.01101903e-04,\n",
       "        6.26201757e-06, 4.71468853e-04, 4.92192936e-04, 8.00967307e-04,\n",
       "        4.90524320e-04, 5.30983387e-07, 4.90193390e-04, 4.00328675e-04,\n",
       "        4.00185681e-04, 4.00519382e-04, 4.90329667e-04, 4.00352563e-04,\n",
       "        4.90426992e-04, 4.90543839e-04, 4.90134984e-04, 4.00376444e-04,\n",
       "        4.90057163e-04, 4.90290718e-04, 3.99923623e-04, 1.21742046e-05,\n",
       "        5.93782007e-04, 4.90271273e-04, 4.00519382e-04, 4.67481126e-04,\n",
       "        4.00305064e-04, 4.00280992e-04, 4.79543715e-04, 4.94786570e-04,\n",
       "        4.92709525e-04, 4.90407542e-04, 3.25997632e-06, 3.99907283e-04,\n",
       "        4.85248652e-04, 4.02569544e-04, 2.78041453e-07, 1.78416128e-07,\n",
       "        4.00138111e-04, 4.90563292e-04, 4.90368632e-04, 4.90232463e-04,\n",
       "        4.90368609e-04, 4.00281020e-04, 4.90329667e-04, 4.00281048e-04,\n",
       "        2.33601546e-07, 3.16297988e-07, 4.90232324e-04, 1.55065083e-03,\n",
       "        4.90272293e-04, 4.01749282e-04, 3.38722241e-06, 4.90271273e-04,\n",
       "        4.00257196e-04, 3.38978757e-04, 6.25851268e-05, 1.83814385e-06,\n",
       "        4.90190885e-04, 3.74387321e-05, 3.70071362e-04, 4.90096089e-04,\n",
       "        1.08672705e-04, 3.98001765e-04, 4.68296901e-04, 3.78321459e-04,\n",
       "        4.02247120e-04, 4.00447845e-04, 5.07060603e-04, 4.38744604e-05,\n",
       "        5.59048814e-05, 4.01638922e-04, 4.90388074e-04, 4.73477650e-04,\n",
       "        4.90329830e-04, 3.36435072e-04, 3.81469727e-07, 2.43140197e-07,\n",
       "        4.90115569e-04, 6.39207992e-05, 4.67816865e-05, 4.00400176e-04,\n",
       "        3.97349420e-04, 4.02268147e-04, 4.00691414e-04, 3.96796236e-04,\n",
       "        4.00280992e-04, 4.00567151e-04, 5.45163567e-05, 3.11020303e-04,\n",
       "        3.99897674e-04, 3.97719735e-04, 4.00209697e-04, 4.89166145e-04,\n",
       "        4.53400621e-04, 4.92092884e-04, 5.14710354e-04, 4.00304865e-04,\n",
       "        8.03292668e-04, 1.09680220e-03, 4.87367629e-04, 4.90232393e-04,\n",
       "        4.00161828e-04, 4.90173941e-04, 4.90212959e-04, 4.90251785e-04,\n",
       "        1.90734863e-07, 4.90193413e-04, 4.00424128e-04, 4.90212867e-04,\n",
       "        4.90251831e-04, 4.00590968e-04, 3.23406696e-07, 4.90310191e-04,\n",
       "        4.00400290e-04, 3.98831297e-04, 4.00567151e-04, 3.50402318e-07,\n",
       "        4.84834587e-04, 4.93516567e-04, 4.90154518e-04, 3.01578299e-07,\n",
       "        3.37174788e-07, 5.12021093e-04, 3.93819823e-04, 3.93606924e-04,\n",
       "        4.01909564e-04, 3.99905151e-04, 4.01014992e-04, 3.99371249e-04,\n",
       "        8.52338384e-05, 4.62310777e-07, 3.99285436e-04, 4.18706861e-04,\n",
       "        4.08393519e-04, 3.49291189e-04, 4.00865108e-04, 3.18055746e-05,\n",
       "        4.89362399e-04, 4.84455650e-04, 4.90271412e-04, 4.90290742e-04,\n",
       "        5.35248383e-07, 4.00328647e-04, 4.90135054e-04, 4.00924768e-04,\n",
       "        5.76164530e-07, 4.90933902e-07, 4.90310376e-04, 8.00728803e-04,\n",
       "        4.00590911e-04, 4.89901406e-04, 4.00281048e-04, 4.90543792e-04,\n",
       "        4.00495543e-04, 4.23176830e-04, 4.00376416e-04, 2.43140197e-07,\n",
       "        4.90290788e-04, 4.00352478e-04, 4.15306622e-04, 4.66822497e-04,\n",
       "        6.38835763e-04, 3.99994889e-04, 3.86385242e-06, 1.90734863e-07,\n",
       "        4.00638609e-04, 4.00376359e-04, 4.90680139e-04, 4.90446515e-04,\n",
       "        4.00304837e-04, 4.90504921e-04, 4.00328675e-04, 4.90193437e-04,\n",
       "        4.90290811e-04, 4.90485479e-04, 4.02196147e-04, 4.00519751e-04,\n",
       "        4.90154750e-04, 4.66643417e-04, 4.90018531e-04, 4.00400176e-04,\n",
       "        4.00447931e-04, 4.90271319e-04, 4.01202029e-04, 1.04432781e-05,\n",
       "        4.00424043e-04, 4.00900965e-04, 4.90115662e-04, 5.00537639e-04,\n",
       "        4.90940789e-04, 4.61729006e-04, 6.07551170e-06, 4.93956609e-04,\n",
       "        3.89830070e-04, 3.91633688e-04, 4.01628874e-04, 4.00519552e-04,\n",
       "        4.91777569e-04, 4.03229115e-04, 4.90368632e-04, 4.02044237e-04,\n",
       "        4.90427038e-04, 4.90349310e-04, 4.00091393e-04, 2.33601546e-07,\n",
       "        4.90135054e-04, 4.90349287e-04, 4.90466134e-04, 4.00543213e-04,\n",
       "        4.00280992e-04, 3.16297988e-07, 3.81469727e-07, 4.90368655e-04,\n",
       "        4.90232324e-04, 2.43140197e-07, 2.86102295e-07, 4.00161772e-04,\n",
       "        4.89998769e-04, 4.15696997e-07, 2.43140197e-07, 2.43140197e-07,\n",
       "        1.00701867e-06, 4.60037668e-04, 4.61170059e-04, 4.21442508e-04,\n",
       "        4.00353018e-04, 3.37604075e-05, 4.90446468e-04, 3.87922793e-04,\n",
       "        2.33601546e-07, 4.00209668e-04, 4.00448044e-04, 4.90329644e-04,\n",
       "        4.00471897e-04, 1.50789149e-07, 3.56832255e-07, 4.90524320e-04,\n",
       "        4.00710145e-04, 4.90797033e-04, 4.10190833e-07, 4.00377069e-04,\n",
       "        2.33601546e-07, 3.99972259e-04, 4.00471840e-04, 4.90660732e-04,\n",
       "        4.00090427e-04, 1.42338887e-05, 5.51978917e-07, 4.00543270e-04,\n",
       "        4.90096135e-04, 4.90290834e-04, 2.13248060e-07, 4.09750213e-04,\n",
       "        3.86913457e-04, 4.70423214e-04, 4.00304951e-04, 4.00472947e-04,\n",
       "        4.90232463e-04, 4.00495572e-04, 1.16800773e-07, 4.00376614e-04,\n",
       "        6.33239075e-04, 4.90018253e-04, 4.00662575e-04, 4.90290788e-04,\n",
       "        3.99994918e-04, 4.00400204e-04, 4.00734146e-04, 4.00424043e-04,\n",
       "        5.36559516e-04, 4.90465972e-04, 4.00519438e-04, 4.15696997e-07,\n",
       "        4.90232579e-04, 4.00233365e-04, 4.90154658e-04, 1.90734863e-07,\n",
       "        4.00400318e-04, 2.22904842e-04, 4.90388120e-04, 4.00280963e-04,\n",
       "        4.90154495e-04, 3.23406696e-07, 4.90271319e-04, 4.42200589e-07,\n",
       "        4.90349194e-04, 4.00376387e-04, 4.90427038e-04, 4.90290765e-04,\n",
       "        4.90427038e-04, 4.00901447e-04, 2.43140197e-07, 4.90719127e-04,\n",
       "        4.00138168e-04, 4.00900851e-04, 4.90563338e-04, 3.56832255e-07,\n",
       "        4.00447874e-04, 5.06737825e-04, 4.76320931e-04, 4.00519410e-04,\n",
       "        3.24599694e-06, 4.87771331e-04, 5.03903893e-04, 5.67527571e-05,\n",
       "        3.90735695e-04, 4.03285178e-04, 4.00185652e-04, 4.16508471e-04,\n",
       "        9.15899797e-06, 4.90430205e-05, 3.99721899e-04, 4.01178475e-04,\n",
       "        2.20549428e-05, 4.07823437e-04, 4.90874769e-04, 1.90734863e-07,\n",
       "        4.90349125e-04, 4.00519637e-04, 4.00447959e-04, 4.90232393e-04,\n",
       "        4.62310777e-07, 4.00304951e-04, 4.90427061e-04, 7.49067385e-04]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'gini', 'gini',\n",
       "                    'gini', 'gini', 'gini', 'gini', 'gini', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy', 'entropy',\n",
       "                    'entropy', 'entropy', 'entropy', 'entropy'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "                    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "                    15, 15, 15, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10,\n",
       "                    10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5,\n",
       "                    10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2,\n",
       "                    5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15,\n",
       "                    2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15,\n",
       "                    15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2, 2, 2, 5, 5, 5,\n",
       "                    5, 5, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 2, 2, 2,\n",
       "                    2, 2, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150, 10, 20, 50, 100, 150, 10, 20, 50, 100, 150,\n",
       "                    10, 20, 50, 100, 150, 10, 20, 50, 100, 150, 10, 20, 50,\n",
       "                    100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 20,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 50,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 1,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 150},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 10},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 20},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 50},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 100},\n",
       "  {'criterion': 'entropy',\n",
       "   'max_depth': 100,\n",
       "   'min_samples_leaf': 15,\n",
       "   'min_samples_split': 15,\n",
       "   'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.64583333, 0.64583333, 0.63541667, 0.64583333, 0.63541667,\n",
       "        0.64583333, 0.66666667, 0.65625   , 0.61458333, 0.63541667,\n",
       "        0.625     , 0.70833333, 0.65625   , 0.625     , 0.625     ,\n",
       "        0.65625   , 0.67708333, 0.60416667, 0.61458333, 0.625     ,\n",
       "        0.66666667, 0.71875   , 0.65625   , 0.625     , 0.65625   ,\n",
       "        0.55208333, 0.61458333, 0.65625   , 0.67708333, 0.64583333,\n",
       "        0.59375   , 0.64583333, 0.64583333, 0.65625   , 0.65625   ,\n",
       "        0.65625   , 0.625     , 0.67708333, 0.65625   , 0.64583333,\n",
       "        0.66666667, 0.63541667, 0.65625   , 0.60416667, 0.63541667,\n",
       "        0.63541667, 0.64583333, 0.60416667, 0.64583333, 0.61458333,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.63541667, 0.63541667,\n",
       "        0.6875    , 0.64583333, 0.66666667, 0.625     , 0.625     ,\n",
       "        0.67708333, 0.61458333, 0.64583333, 0.63541667, 0.63541667,\n",
       "        0.53125   , 0.64583333, 0.5625    , 0.60416667, 0.60416667,\n",
       "        0.625     , 0.63541667, 0.625     , 0.67708333, 0.625     ,\n",
       "        0.61458333, 0.60416667, 0.66666667, 0.59375   , 0.625     ,\n",
       "        0.67708333, 0.67708333, 0.65625   , 0.65625   , 0.63541667,\n",
       "        0.625     , 0.64583333, 0.625     , 0.65625   , 0.61458333,\n",
       "        0.625     , 0.64583333, 0.61458333, 0.65625   , 0.61458333,\n",
       "        0.58333333, 0.69791667, 0.58333333, 0.63541667, 0.66666667,\n",
       "        0.66666667, 0.63541667, 0.63541667, 0.61458333, 0.63541667,\n",
       "        0.61458333, 0.63541667, 0.66666667, 0.63541667, 0.65625   ,\n",
       "        0.61458333, 0.64583333, 0.65625   , 0.64583333, 0.65625   ,\n",
       "        0.65625   , 0.70833333, 0.66666667, 0.63541667, 0.63541667,\n",
       "        0.625     , 0.69791667, 0.625     , 0.625     , 0.64583333,\n",
       "        0.55208333, 0.6875    , 0.625     , 0.625     , 0.64583333,\n",
       "        0.63541667, 0.70833333, 0.625     , 0.63541667, 0.61458333,\n",
       "        0.63541667, 0.66666667, 0.64583333, 0.63541667, 0.61458333,\n",
       "        0.60416667, 0.625     , 0.63541667, 0.625     , 0.59375   ,\n",
       "        0.63541667, 0.58333333, 0.65625   , 0.65625   , 0.61458333,\n",
       "        0.59375   , 0.63541667, 0.65625   , 0.63541667, 0.625     ,\n",
       "        0.67708333, 0.64583333, 0.60416667, 0.61458333, 0.63541667,\n",
       "        0.65625   , 0.66666667, 0.66666667, 0.65625   , 0.60416667,\n",
       "        0.61458333, 0.65625   , 0.65625   , 0.67708333, 0.60416667,\n",
       "        0.625     , 0.57291667, 0.67708333, 0.66666667, 0.625     ,\n",
       "        0.65625   , 0.60416667, 0.65625   , 0.69791667, 0.63541667,\n",
       "        0.5625    , 0.66666667, 0.63541667, 0.58333333, 0.67708333,\n",
       "        0.65625   , 0.64583333, 0.67708333, 0.625     , 0.59375   ,\n",
       "        0.625     , 0.63541667, 0.65625   , 0.64583333, 0.58333333,\n",
       "        0.6875    , 0.69791667, 0.64583333, 0.64583333, 0.65625   ,\n",
       "        0.59375   , 0.6875    , 0.63541667, 0.61458333, 0.65625   ,\n",
       "        0.64583333, 0.61458333, 0.67708333, 0.65625   , 0.63541667,\n",
       "        0.61458333, 0.6875    , 0.61458333, 0.61458333, 0.625     ,\n",
       "        0.61458333, 0.625     , 0.64583333, 0.625     , 0.63541667,\n",
       "        0.70833333, 0.63541667, 0.63541667, 0.60416667, 0.60416667,\n",
       "        0.57291667, 0.64583333, 0.625     , 0.63541667, 0.63541667,\n",
       "        0.53125   , 0.6875    , 0.63541667, 0.61458333, 0.625     ,\n",
       "        0.53125   , 0.65625   , 0.65625   , 0.60416667, 0.625     ,\n",
       "        0.61458333, 0.66666667, 0.59375   , 0.63541667, 0.64583333,\n",
       "        0.61458333, 0.65625   , 0.63541667, 0.66666667, 0.65625   ,\n",
       "        0.63541667, 0.65625   , 0.64583333, 0.65625   , 0.64583333,\n",
       "        0.70833333, 0.625     , 0.61458333, 0.64583333, 0.64583333,\n",
       "        0.63541667, 0.65625   , 0.65625   , 0.64583333, 0.65625   ,\n",
       "        0.63541667, 0.58333333, 0.65625   , 0.625     , 0.63541667,\n",
       "        0.60416667, 0.6875    , 0.61458333, 0.63541667, 0.64583333,\n",
       "        0.65625   , 0.625     , 0.64583333, 0.66666667, 0.64583333,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.60416667, 0.63541667,\n",
       "        0.61458333, 0.69791667, 0.65625   , 0.60416667, 0.66666667,\n",
       "        0.64583333, 0.64583333, 0.60416667, 0.59375   , 0.64583333,\n",
       "        0.66666667, 0.64583333, 0.625     , 0.65625   , 0.64583333,\n",
       "        0.57291667, 0.6875    , 0.65625   , 0.65625   , 0.625     ,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.61458333, 0.63541667,\n",
       "        0.65625   , 0.60416667, 0.63541667, 0.6875    , 0.59375   ,\n",
       "        0.66666667, 0.63541667, 0.63541667, 0.61458333, 0.625     ,\n",
       "        0.60416667, 0.64583333, 0.65625   , 0.60416667, 0.65625   ,\n",
       "        0.69791667, 0.61458333, 0.61458333, 0.63541667, 0.61458333,\n",
       "        0.69791667, 0.65625   , 0.66666667, 0.63541667, 0.625     ,\n",
       "        0.59375   , 0.65625   , 0.65625   , 0.64583333, 0.67708333,\n",
       "        0.60416667, 0.63541667, 0.69791667, 0.64583333, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.61458333, 0.63541667, 0.63541667,\n",
       "        0.625     , 0.66666667, 0.60416667, 0.66666667, 0.66666667,\n",
       "        0.60416667, 0.6875    , 0.61458333, 0.66666667, 0.64583333,\n",
       "        0.60416667, 0.60416667, 0.60416667, 0.63541667, 0.65625   ,\n",
       "        0.59375   , 0.58333333, 0.66666667, 0.64583333, 0.60416667,\n",
       "        0.625     , 0.60416667, 0.625     , 0.61458333, 0.65625   ,\n",
       "        0.63541667, 0.6875    , 0.60416667, 0.66666667, 0.625     ,\n",
       "        0.63541667, 0.65625   , 0.67708333, 0.63541667, 0.61458333,\n",
       "        0.59375   , 0.64583333, 0.64583333, 0.67708333, 0.66666667,\n",
       "        0.67708333, 0.63541667, 0.67708333, 0.66666667, 0.63541667,\n",
       "        0.63541667, 0.70833333, 0.6875    , 0.66666667, 0.625     ,\n",
       "        0.67708333, 0.65625   , 0.64583333, 0.65625   , 0.63541667,\n",
       "        0.60416667, 0.66666667, 0.65625   , 0.64583333, 0.60416667,\n",
       "        0.66666667, 0.66666667, 0.65625   , 0.67708333, 0.61458333,\n",
       "        0.61458333, 0.625     , 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.63541667, 0.65625   , 0.65625   , 0.67708333, 0.65625   ,\n",
       "        0.71875   , 0.61458333, 0.65625   , 0.64583333, 0.64583333,\n",
       "        0.60416667, 0.71875   , 0.65625   , 0.66666667, 0.625     ,\n",
       "        0.72916667, 0.63541667, 0.625     , 0.66666667, 0.67708333,\n",
       "        0.64583333, 0.63541667, 0.66666667, 0.625     , 0.61458333,\n",
       "        0.6875    , 0.64583333, 0.65625   , 0.61458333, 0.64583333,\n",
       "        0.625     , 0.64583333, 0.66666667, 0.625     , 0.66666667,\n",
       "        0.60416667, 0.58333333, 0.69791667, 0.65625   , 0.63541667,\n",
       "        0.625     , 0.69791667, 0.64583333, 0.625     , 0.61458333,\n",
       "        0.64583333, 0.69791667, 0.66666667, 0.625     , 0.625     ,\n",
       "        0.6875    , 0.64583333, 0.61458333, 0.64583333, 0.625     ,\n",
       "        0.66666667, 0.63541667, 0.65625   , 0.63541667, 0.63541667,\n",
       "        0.65625   , 0.625     , 0.6875    , 0.65625   , 0.64583333,\n",
       "        0.65625   , 0.60416667, 0.65625   , 0.67708333, 0.67708333,\n",
       "        0.59375   , 0.66666667, 0.625     , 0.6875    , 0.65625   ,\n",
       "        0.71875   , 0.69791667, 0.60416667, 0.63541667, 0.65625   ,\n",
       "        0.65625   , 0.63541667, 0.61458333, 0.63541667, 0.63541667,\n",
       "        0.61458333, 0.64583333, 0.67708333, 0.63541667, 0.63541667,\n",
       "        0.63541667, 0.59375   , 0.66666667, 0.625     , 0.625     ,\n",
       "        0.59375   , 0.65625   , 0.66666667, 0.64583333, 0.69791667,\n",
       "        0.58333333, 0.58333333, 0.65625   , 0.61458333, 0.63541667,\n",
       "        0.57291667, 0.66666667, 0.63541667, 0.66666667, 0.61458333,\n",
       "        0.60416667, 0.65625   , 0.66666667, 0.64583333, 0.66666667,\n",
       "        0.59375   , 0.625     , 0.63541667, 0.63541667, 0.58333333,\n",
       "        0.55208333, 0.55208333, 0.625     , 0.66666667, 0.63541667,\n",
       "        0.58333333, 0.64583333, 0.67708333, 0.64583333, 0.64583333,\n",
       "        0.625     , 0.64583333, 0.65625   , 0.64583333, 0.61458333,\n",
       "        0.60416667, 0.5625    , 0.625     , 0.64583333, 0.66666667,\n",
       "        0.60416667, 0.64583333, 0.64583333, 0.66666667, 0.61458333,\n",
       "        0.67708333, 0.625     , 0.64583333, 0.625     , 0.60416667,\n",
       "        0.65625   , 0.625     , 0.63541667, 0.625     , 0.63541667,\n",
       "        0.625     , 0.66666667, 0.64583333, 0.64583333, 0.63541667,\n",
       "        0.67708333, 0.66666667, 0.66666667, 0.625     , 0.625     ,\n",
       "        0.63541667, 0.63541667, 0.60416667, 0.64583333, 0.64583333,\n",
       "        0.66666667, 0.65625   , 0.67708333, 0.63541667, 0.63541667,\n",
       "        0.67708333, 0.67708333, 0.60416667, 0.64583333, 0.65625   ,\n",
       "        0.65625   , 0.60416667, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.54166667, 0.63541667, 0.61458333, 0.63541667, 0.64583333,\n",
       "        0.66666667, 0.65625   , 0.67708333, 0.63541667, 0.64583333,\n",
       "        0.63541667, 0.69791667, 0.57291667, 0.65625   , 0.66666667,\n",
       "        0.57291667, 0.60416667, 0.67708333, 0.63541667, 0.63541667,\n",
       "        0.65625   , 0.64583333, 0.64583333, 0.60416667, 0.65625   ,\n",
       "        0.63541667, 0.60416667, 0.66666667, 0.63541667, 0.61458333,\n",
       "        0.61458333, 0.60416667, 0.63541667, 0.60416667, 0.625     ]),\n",
       " 'split1_test_score': array([0.64583333, 0.55208333, 0.64583333, 0.63541667, 0.64583333,\n",
       "        0.65625   , 0.64583333, 0.63541667, 0.625     , 0.59375   ,\n",
       "        0.60416667, 0.6875    , 0.66666667, 0.64583333, 0.63541667,\n",
       "        0.69791667, 0.66666667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.625     , 0.65625   , 0.67708333, 0.66666667, 0.64583333,\n",
       "        0.63541667, 0.66666667, 0.67708333, 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.64583333, 0.67708333, 0.66666667, 0.65625   ,\n",
       "        0.61458333, 0.6875    , 0.69791667, 0.66666667, 0.65625   ,\n",
       "        0.69791667, 0.72916667, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.71875   , 0.70833333, 0.69791667, 0.66666667, 0.70833333,\n",
       "        0.63541667, 0.72916667, 0.66666667, 0.67708333, 0.73958333,\n",
       "        0.65625   , 0.67708333, 0.70833333, 0.70833333, 0.71875   ,\n",
       "        0.71875   , 0.69791667, 0.73958333, 0.69791667, 0.6875    ,\n",
       "        0.64583333, 0.75      , 0.69791667, 0.70833333, 0.69791667,\n",
       "        0.76041667, 0.6875    , 0.70833333, 0.69791667, 0.67708333,\n",
       "        0.75      , 0.75      , 0.69791667, 0.65625   , 0.6875    ,\n",
       "        0.53125   , 0.65625   , 0.63541667, 0.60416667, 0.625     ,\n",
       "        0.5625    , 0.63541667, 0.65625   , 0.625     , 0.63541667,\n",
       "        0.65625   , 0.63541667, 0.65625   , 0.625     , 0.63541667,\n",
       "        0.64583333, 0.60416667, 0.6875    , 0.64583333, 0.67708333,\n",
       "        0.66666667, 0.70833333, 0.67708333, 0.66666667, 0.65625   ,\n",
       "        0.64583333, 0.625     , 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.67708333, 0.75      , 0.69791667, 0.63541667, 0.65625   ,\n",
       "        0.66666667, 0.67708333, 0.67708333, 0.6875    , 0.65625   ,\n",
       "        0.66666667, 0.71875   , 0.65625   , 0.67708333, 0.6875    ,\n",
       "        0.65625   , 0.73958333, 0.69791667, 0.67708333, 0.70833333,\n",
       "        0.73958333, 0.64583333, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.71875   , 0.69791667, 0.73958333, 0.69791667, 0.65625   ,\n",
       "        0.71875   , 0.69791667, 0.6875    , 0.69791667, 0.69791667,\n",
       "        0.77083333, 0.73958333, 0.72916667, 0.66666667, 0.67708333,\n",
       "        0.69791667, 0.72916667, 0.72916667, 0.67708333, 0.65625   ,\n",
       "        0.71875   , 0.6875    , 0.71875   , 0.69791667, 0.69791667,\n",
       "        0.65625   , 0.59375   , 0.61458333, 0.60416667, 0.625     ,\n",
       "        0.64583333, 0.63541667, 0.64583333, 0.61458333, 0.64583333,\n",
       "        0.625     , 0.65625   , 0.65625   , 0.64583333, 0.63541667,\n",
       "        0.66666667, 0.6875    , 0.66666667, 0.67708333, 0.66666667,\n",
       "        0.66666667, 0.65625   , 0.65625   , 0.69791667, 0.65625   ,\n",
       "        0.70833333, 0.625     , 0.71875   , 0.6875    , 0.6875    ,\n",
       "        0.69791667, 0.625     , 0.63541667, 0.6875    , 0.64583333,\n",
       "        0.61458333, 0.67708333, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.71875   , 0.63541667, 0.69791667, 0.70833333, 0.66666667,\n",
       "        0.73958333, 0.78125   , 0.69791667, 0.65625   , 0.67708333,\n",
       "        0.73958333, 0.73958333, 0.71875   , 0.71875   , 0.6875    ,\n",
       "        0.67708333, 0.64583333, 0.70833333, 0.6875    , 0.69791667,\n",
       "        0.69791667, 0.76041667, 0.71875   , 0.71875   , 0.71875   ,\n",
       "        0.71875   , 0.69791667, 0.67708333, 0.67708333, 0.71875   ,\n",
       "        0.63541667, 0.72916667, 0.65625   , 0.65625   , 0.6875    ,\n",
       "        0.69791667, 0.75      , 0.75      , 0.66666667, 0.69791667,\n",
       "        0.66666667, 0.58333333, 0.625     , 0.64583333, 0.60416667,\n",
       "        0.65625   , 0.66666667, 0.65625   , 0.67708333, 0.63541667,\n",
       "        0.625     , 0.65625   , 0.625     , 0.625     , 0.625     ,\n",
       "        0.71875   , 0.625     , 0.67708333, 0.65625   , 0.67708333,\n",
       "        0.66666667, 0.67708333, 0.6875    , 0.67708333, 0.64583333,\n",
       "        0.65625   , 0.63541667, 0.6875    , 0.66666667, 0.65625   ,\n",
       "        0.71875   , 0.6875    , 0.66666667, 0.66666667, 0.69791667,\n",
       "        0.67708333, 0.66666667, 0.64583333, 0.66666667, 0.67708333,\n",
       "        0.6875    , 0.6875    , 0.70833333, 0.69791667, 0.66666667,\n",
       "        0.6875    , 0.65625   , 0.63541667, 0.69791667, 0.65625   ,\n",
       "        0.65625   , 0.71875   , 0.73958333, 0.70833333, 0.71875   ,\n",
       "        0.6875    , 0.65625   , 0.69791667, 0.69791667, 0.67708333,\n",
       "        0.65625   , 0.73958333, 0.70833333, 0.64583333, 0.6875    ,\n",
       "        0.70833333, 0.73958333, 0.66666667, 0.70833333, 0.66666667,\n",
       "        0.71875   , 0.66666667, 0.69791667, 0.72916667, 0.6875    ,\n",
       "        0.71875   , 0.70833333, 0.66666667, 0.70833333, 0.66666667,\n",
       "        0.63541667, 0.625     , 0.64583333, 0.58333333, 0.64583333,\n",
       "        0.72916667, 0.63541667, 0.65625   , 0.6875    , 0.65625   ,\n",
       "        0.67708333, 0.58333333, 0.60416667, 0.65625   , 0.625     ,\n",
       "        0.6875    , 0.67708333, 0.625     , 0.64583333, 0.64583333,\n",
       "        0.63541667, 0.65625   , 0.63541667, 0.65625   , 0.64583333,\n",
       "        0.64583333, 0.64583333, 0.6875    , 0.63541667, 0.64583333,\n",
       "        0.6875    , 0.71875   , 0.63541667, 0.64583333, 0.65625   ,\n",
       "        0.64583333, 0.65625   , 0.66666667, 0.71875   , 0.65625   ,\n",
       "        0.66666667, 0.6875    , 0.67708333, 0.66666667, 0.66666667,\n",
       "        0.70833333, 0.6875    , 0.64583333, 0.65625   , 0.65625   ,\n",
       "        0.64583333, 0.67708333, 0.65625   , 0.65625   , 0.70833333,\n",
       "        0.70833333, 0.67708333, 0.70833333, 0.66666667, 0.67708333,\n",
       "        0.65625   , 0.71875   , 0.66666667, 0.65625   , 0.6875    ,\n",
       "        0.73958333, 0.71875   , 0.65625   , 0.6875    , 0.66666667,\n",
       "        0.67708333, 0.6875    , 0.6875    , 0.67708333, 0.65625   ,\n",
       "        0.6875    , 0.70833333, 0.67708333, 0.64583333, 0.67708333,\n",
       "        0.625     , 0.64583333, 0.64583333, 0.65625   , 0.60416667,\n",
       "        0.66666667, 0.61458333, 0.64583333, 0.65625   , 0.60416667,\n",
       "        0.63541667, 0.71875   , 0.69791667, 0.6875    , 0.63541667,\n",
       "        0.6875    , 0.6875    , 0.6875    , 0.64583333, 0.66666667,\n",
       "        0.75      , 0.67708333, 0.66666667, 0.64583333, 0.67708333,\n",
       "        0.69791667, 0.67708333, 0.69791667, 0.67708333, 0.67708333,\n",
       "        0.72916667, 0.64583333, 0.66666667, 0.66666667, 0.64583333,\n",
       "        0.66666667, 0.64583333, 0.71875   , 0.67708333, 0.65625   ,\n",
       "        0.66666667, 0.66666667, 0.66666667, 0.65625   , 0.65625   ,\n",
       "        0.66666667, 0.67708333, 0.64583333, 0.67708333, 0.65625   ,\n",
       "        0.625     , 0.64583333, 0.64583333, 0.67708333, 0.67708333,\n",
       "        0.69791667, 0.64583333, 0.63541667, 0.67708333, 0.65625   ,\n",
       "        0.69791667, 0.6875    , 0.6875    , 0.65625   , 0.65625   ,\n",
       "        0.6875    , 0.70833333, 0.66666667, 0.66666667, 0.64583333,\n",
       "        0.67708333, 0.72916667, 0.65625   , 0.65625   , 0.66666667,\n",
       "        0.66666667, 0.71875   , 0.69791667, 0.66666667, 0.69791667,\n",
       "        0.58333333, 0.64583333, 0.66666667, 0.59375   , 0.60416667,\n",
       "        0.60416667, 0.6875    , 0.625     , 0.67708333, 0.63541667,\n",
       "        0.59375   , 0.64583333, 0.65625   , 0.63541667, 0.66666667,\n",
       "        0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.69791667, 0.64583333, 0.65625   , 0.63541667, 0.67708333,\n",
       "        0.64583333, 0.63541667, 0.6875    , 0.66666667, 0.66666667,\n",
       "        0.6875    , 0.66666667, 0.67708333, 0.66666667, 0.66666667,\n",
       "        0.65625   , 0.64583333, 0.65625   , 0.60416667, 0.67708333,\n",
       "        0.65625   , 0.6875    , 0.63541667, 0.69791667, 0.66666667,\n",
       "        0.69791667, 0.6875    , 0.67708333, 0.65625   , 0.66666667,\n",
       "        0.64583333, 0.67708333, 0.66666667, 0.6875    , 0.69791667,\n",
       "        0.65625   , 0.63541667, 0.65625   , 0.6875    , 0.64583333,\n",
       "        0.70833333, 0.69791667, 0.67708333, 0.65625   , 0.66666667,\n",
       "        0.6875    , 0.64583333, 0.6875    , 0.70833333, 0.66666667,\n",
       "        0.69791667, 0.72916667, 0.6875    , 0.66666667, 0.66666667,\n",
       "        0.73958333, 0.60416667, 0.65625   , 0.6875    , 0.64583333,\n",
       "        0.60416667, 0.61458333, 0.59375   , 0.625     , 0.59375   ,\n",
       "        0.5625    , 0.59375   , 0.63541667, 0.63541667, 0.65625   ,\n",
       "        0.65625   , 0.64583333, 0.65625   , 0.63541667, 0.66666667,\n",
       "        0.66666667, 0.63541667, 0.67708333, 0.67708333, 0.64583333,\n",
       "        0.66666667, 0.65625   , 0.66666667, 0.61458333, 0.65625   ,\n",
       "        0.65625   , 0.69791667, 0.66666667, 0.64583333, 0.65625   ,\n",
       "        0.59375   , 0.6875    , 0.6875    , 0.67708333, 0.61458333,\n",
       "        0.6875    , 0.65625   , 0.66666667, 0.66666667, 0.67708333,\n",
       "        0.66666667, 0.64583333, 0.66666667, 0.64583333, 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.6875    , 0.67708333,\n",
       "        0.65625   , 0.69791667, 0.65625   , 0.67708333, 0.66666667,\n",
       "        0.66666667, 0.67708333, 0.6875    , 0.65625   , 0.63541667,\n",
       "        0.63541667, 0.66666667, 0.6875    , 0.66666667, 0.65625   ,\n",
       "        0.71875   , 0.75      , 0.6875    , 0.64583333, 0.66666667,\n",
       "        0.65625   , 0.66666667, 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.75      , 0.69791667, 0.73958333, 0.65625   , 0.66666667]),\n",
       " 'split2_test_score': array([0.63541667, 0.625     , 0.69791667, 0.69791667, 0.66666667,\n",
       "        0.6875    , 0.63541667, 0.625     , 0.6875    , 0.67708333,\n",
       "        0.58333333, 0.71875   , 0.65625   , 0.69791667, 0.66666667,\n",
       "        0.66666667, 0.67708333, 0.69791667, 0.67708333, 0.66666667,\n",
       "        0.63541667, 0.69791667, 0.6875    , 0.69791667, 0.75      ,\n",
       "        0.625     , 0.66666667, 0.66666667, 0.67708333, 0.71875   ,\n",
       "        0.59375   , 0.67708333, 0.6875    , 0.72916667, 0.69791667,\n",
       "        0.6875    , 0.66666667, 0.6875    , 0.67708333, 0.70833333,\n",
       "        0.66666667, 0.76041667, 0.71875   , 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.63541667, 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.65625   , 0.64583333, 0.6875    , 0.6875    , 0.70833333,\n",
       "        0.67708333, 0.69791667, 0.67708333, 0.6875    , 0.70833333,\n",
       "        0.625     , 0.67708333, 0.69791667, 0.70833333, 0.67708333,\n",
       "        0.6875    , 0.67708333, 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.63541667, 0.66666667, 0.69791667, 0.66666667, 0.70833333,\n",
       "        0.64583333, 0.65625   , 0.6875    , 0.70833333, 0.6875    ,\n",
       "        0.64583333, 0.61458333, 0.6875    , 0.625     , 0.67708333,\n",
       "        0.67708333, 0.69791667, 0.6875    , 0.76041667, 0.71875   ,\n",
       "        0.60416667, 0.6875    , 0.6875    , 0.6875    , 0.71875   ,\n",
       "        0.58333333, 0.67708333, 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.625     , 0.61458333, 0.72916667, 0.67708333, 0.69791667,\n",
       "        0.59375   , 0.73958333, 0.63541667, 0.71875   , 0.71875   ,\n",
       "        0.63541667, 0.65625   , 0.70833333, 0.6875    , 0.70833333,\n",
       "        0.52083333, 0.65625   , 0.66666667, 0.67708333, 0.69791667,\n",
       "        0.6875    , 0.70833333, 0.71875   , 0.69791667, 0.70833333,\n",
       "        0.65625   , 0.6875    , 0.70833333, 0.69791667, 0.69791667,\n",
       "        0.69791667, 0.71875   , 0.65625   , 0.65625   , 0.70833333,\n",
       "        0.52083333, 0.625     , 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.67708333, 0.64583333, 0.65625   , 0.71875   , 0.67708333,\n",
       "        0.66666667, 0.69791667, 0.64583333, 0.65625   , 0.6875    ,\n",
       "        0.625     , 0.69791667, 0.66666667, 0.65625   , 0.6875    ,\n",
       "        0.59375   , 0.65625   , 0.67708333, 0.66666667, 0.69791667,\n",
       "        0.63541667, 0.61458333, 0.65625   , 0.71875   , 0.69791667,\n",
       "        0.61458333, 0.65625   , 0.73958333, 0.69791667, 0.71875   ,\n",
       "        0.60416667, 0.60416667, 0.69791667, 0.69791667, 0.67708333,\n",
       "        0.625     , 0.75      , 0.66666667, 0.66666667, 0.71875   ,\n",
       "        0.5625    , 0.75      , 0.67708333, 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.66666667, 0.69791667, 0.6875    , 0.70833333,\n",
       "        0.59375   , 0.66666667, 0.6875    , 0.69791667, 0.70833333,\n",
       "        0.60416667, 0.71875   , 0.69791667, 0.70833333, 0.6875    ,\n",
       "        0.66666667, 0.66666667, 0.6875    , 0.6875    , 0.73958333,\n",
       "        0.6875    , 0.64583333, 0.71875   , 0.70833333, 0.69791667,\n",
       "        0.65625   , 0.65625   , 0.6875    , 0.65625   , 0.67708333,\n",
       "        0.59375   , 0.70833333, 0.73958333, 0.6875    , 0.67708333,\n",
       "        0.71875   , 0.64583333, 0.65625   , 0.70833333, 0.67708333,\n",
       "        0.65625   , 0.63541667, 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.72916667, 0.64583333, 0.66666667, 0.64583333, 0.6875    ,\n",
       "        0.625     , 0.69791667, 0.70833333, 0.65625   , 0.67708333,\n",
       "        0.59375   , 0.64583333, 0.64583333, 0.66666667, 0.72916667,\n",
       "        0.64583333, 0.60416667, 0.67708333, 0.69791667, 0.70833333,\n",
       "        0.63541667, 0.65625   , 0.66666667, 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.625     , 0.6875    , 0.66666667, 0.67708333,\n",
       "        0.625     , 0.67708333, 0.67708333, 0.73958333, 0.67708333,\n",
       "        0.67708333, 0.67708333, 0.6875    , 0.69791667, 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.69791667, 0.6875    , 0.71875   ,\n",
       "        0.65625   , 0.67708333, 0.64583333, 0.72916667, 0.69791667,\n",
       "        0.70833333, 0.65625   , 0.72916667, 0.65625   , 0.70833333,\n",
       "        0.58333333, 0.64583333, 0.72916667, 0.69791667, 0.6875    ,\n",
       "        0.59375   , 0.6875    , 0.6875    , 0.69791667, 0.71875   ,\n",
       "        0.67708333, 0.67708333, 0.67708333, 0.70833333, 0.6875    ,\n",
       "        0.65625   , 0.71875   , 0.63541667, 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.65625   , 0.64583333, 0.66666667, 0.70833333,\n",
       "        0.61458333, 0.73958333, 0.69791667, 0.69791667, 0.6875    ,\n",
       "        0.65625   , 0.65625   , 0.70833333, 0.66666667, 0.71875   ,\n",
       "        0.63541667, 0.67708333, 0.65625   , 0.6875    , 0.6875    ,\n",
       "        0.59375   , 0.63541667, 0.63541667, 0.66666667, 0.66666667,\n",
       "        0.64583333, 0.64583333, 0.65625   , 0.66666667, 0.69791667,\n",
       "        0.61458333, 0.65625   , 0.6875    , 0.6875    , 0.67708333,\n",
       "        0.64583333, 0.625     , 0.6875    , 0.66666667, 0.67708333,\n",
       "        0.67708333, 0.65625   , 0.66666667, 0.65625   , 0.6875    ,\n",
       "        0.65625   , 0.64583333, 0.69791667, 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.65625   , 0.63541667, 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.71875   , 0.67708333, 0.67708333, 0.65625   ,\n",
       "        0.64583333, 0.65625   , 0.67708333, 0.67708333, 0.67708333,\n",
       "        0.61458333, 0.73958333, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.67708333, 0.65625   , 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.66666667, 0.60416667, 0.66666667, 0.66666667, 0.6875    ,\n",
       "        0.60416667, 0.63541667, 0.66666667, 0.6875    , 0.66666667,\n",
       "        0.61458333, 0.70833333, 0.64583333, 0.61458333, 0.67708333,\n",
       "        0.72916667, 0.65625   , 0.69791667, 0.66666667, 0.70833333,\n",
       "        0.64583333, 0.6875    , 0.64583333, 0.69791667, 0.70833333,\n",
       "        0.66666667, 0.66666667, 0.69791667, 0.64583333, 0.69791667,\n",
       "        0.63541667, 0.70833333, 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.63541667, 0.6875    , 0.67708333, 0.65625   , 0.66666667,\n",
       "        0.59375   , 0.66666667, 0.69791667, 0.67708333, 0.70833333,\n",
       "        0.61458333, 0.67708333, 0.67708333, 0.6875    , 0.67708333,\n",
       "        0.57291667, 0.70833333, 0.69791667, 0.69791667, 0.69791667,\n",
       "        0.625     , 0.58333333, 0.66666667, 0.69791667, 0.6875    ,\n",
       "        0.63541667, 0.69791667, 0.64583333, 0.67708333, 0.6875    ,\n",
       "        0.625     , 0.63541667, 0.66666667, 0.67708333, 0.6875    ,\n",
       "        0.63541667, 0.67708333, 0.6875    , 0.66666667, 0.64583333,\n",
       "        0.65625   , 0.66666667, 0.6875    , 0.65625   , 0.67708333,\n",
       "        0.70833333, 0.71875   , 0.67708333, 0.63541667, 0.70833333,\n",
       "        0.69791667, 0.69791667, 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.625     , 0.65625   , 0.63541667, 0.69791667, 0.66666667,\n",
       "        0.625     , 0.6875    , 0.67708333, 0.69791667, 0.6875    ,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.75      , 0.70833333,\n",
       "        0.70833333, 0.65625   , 0.6875    , 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.69791667, 0.69791667, 0.6875    , 0.66666667,\n",
       "        0.6875    , 0.66666667, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.65625   , 0.70833333, 0.65625   , 0.6875    , 0.65625   ,\n",
       "        0.66666667, 0.66666667, 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.6875    , 0.64583333, 0.66666667, 0.66666667, 0.65625   ,\n",
       "        0.67708333, 0.70833333, 0.65625   , 0.70833333, 0.6875    ,\n",
       "        0.67708333, 0.6875    , 0.6875    , 0.65625   , 0.67708333,\n",
       "        0.70833333, 0.64583333, 0.63541667, 0.71875   , 0.66666667,\n",
       "        0.70833333, 0.66666667, 0.6875    , 0.6875    , 0.69791667,\n",
       "        0.66666667, 0.69791667, 0.66666667, 0.67708333, 0.67708333,\n",
       "        0.61458333, 0.65625   , 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.72916667, 0.64583333, 0.6875    , 0.65625   , 0.67708333,\n",
       "        0.66666667, 0.6875    , 0.71875   , 0.69791667, 0.6875    ,\n",
       "        0.57291667, 0.64583333, 0.6875    , 0.67708333, 0.6875    ,\n",
       "        0.65625   , 0.66666667, 0.70833333, 0.67708333, 0.67708333,\n",
       "        0.625     , 0.6875    , 0.67708333, 0.71875   , 0.66666667,\n",
       "        0.65625   , 0.67708333, 0.67708333, 0.71875   , 0.69791667,\n",
       "        0.63541667, 0.6875    , 0.69791667, 0.65625   , 0.67708333,\n",
       "        0.64583333, 0.66666667, 0.70833333, 0.70833333, 0.66666667,\n",
       "        0.625     , 0.63541667, 0.67708333, 0.6875    , 0.6875    ,\n",
       "        0.65625   , 0.6875    , 0.69791667, 0.66666667, 0.64583333,\n",
       "        0.63541667, 0.66666667, 0.6875    , 0.67708333, 0.67708333,\n",
       "        0.64583333, 0.64583333, 0.67708333, 0.6875    , 0.65625   ,\n",
       "        0.65625   , 0.63541667, 0.66666667, 0.69791667, 0.67708333,\n",
       "        0.67708333, 0.66666667, 0.66666667, 0.6875    , 0.6875    ,\n",
       "        0.64583333, 0.73958333, 0.6875    , 0.69791667, 0.6875    ,\n",
       "        0.64583333, 0.59375   , 0.67708333, 0.66666667, 0.67708333,\n",
       "        0.69791667, 0.67708333, 0.70833333, 0.70833333, 0.6875    ,\n",
       "        0.625     , 0.625     , 0.67708333, 0.69791667, 0.6875    ,\n",
       "        0.60416667, 0.70833333, 0.70833333, 0.67708333, 0.69791667]),\n",
       " 'split3_test_score': array([0.64583333, 0.71875   , 0.76041667, 0.77083333, 0.78125   ,\n",
       "        0.66666667, 0.6875    , 0.75      , 0.79166667, 0.76041667,\n",
       "        0.6875    , 0.79166667, 0.72916667, 0.79166667, 0.77083333,\n",
       "        0.6875    , 0.70833333, 0.73958333, 0.80208333, 0.78125   ,\n",
       "        0.76041667, 0.76041667, 0.76041667, 0.77083333, 0.76041667,\n",
       "        0.69791667, 0.71875   , 0.79166667, 0.76041667, 0.73958333,\n",
       "        0.70833333, 0.70833333, 0.70833333, 0.77083333, 0.76041667,\n",
       "        0.71875   , 0.67708333, 0.76041667, 0.79166667, 0.77083333,\n",
       "        0.65625   , 0.76041667, 0.75      , 0.73958333, 0.73958333,\n",
       "        0.71875   , 0.76041667, 0.78125   , 0.76041667, 0.73958333,\n",
       "        0.71875   , 0.65625   , 0.72916667, 0.73958333, 0.73958333,\n",
       "        0.70833333, 0.72916667, 0.73958333, 0.77083333, 0.77083333,\n",
       "        0.69791667, 0.69791667, 0.72916667, 0.76041667, 0.73958333,\n",
       "        0.79166667, 0.69791667, 0.70833333, 0.73958333, 0.70833333,\n",
       "        0.69791667, 0.6875    , 0.77083333, 0.75      , 0.75      ,\n",
       "        0.76041667, 0.76041667, 0.73958333, 0.75      , 0.75      ,\n",
       "        0.79166667, 0.78125   , 0.77083333, 0.75      , 0.75      ,\n",
       "        0.72916667, 0.6875    , 0.75      , 0.77083333, 0.76041667,\n",
       "        0.64583333, 0.6875    , 0.72916667, 0.78125   , 0.77083333,\n",
       "        0.72916667, 0.78125   , 0.73958333, 0.78125   , 0.76041667,\n",
       "        0.76041667, 0.72916667, 0.75      , 0.78125   , 0.75      ,\n",
       "        0.71875   , 0.72916667, 0.75      , 0.77083333, 0.73958333,\n",
       "        0.69791667, 0.67708333, 0.76041667, 0.77083333, 0.73958333,\n",
       "        0.75      , 0.77083333, 0.77083333, 0.78125   , 0.77083333,\n",
       "        0.73958333, 0.73958333, 0.73958333, 0.72916667, 0.75      ,\n",
       "        0.71875   , 0.77083333, 0.76041667, 0.73958333, 0.77083333,\n",
       "        0.75      , 0.71875   , 0.71875   , 0.73958333, 0.77083333,\n",
       "        0.6875    , 0.73958333, 0.76041667, 0.75      , 0.75      ,\n",
       "        0.72916667, 0.66666667, 0.72916667, 0.80208333, 0.76041667,\n",
       "        0.76041667, 0.73958333, 0.67708333, 0.70833333, 0.72916667,\n",
       "        0.77083333, 0.76041667, 0.75      , 0.72916667, 0.77083333,\n",
       "        0.61458333, 0.71875   , 0.75      , 0.73958333, 0.73958333,\n",
       "        0.65625   , 0.73958333, 0.71875   , 0.72916667, 0.73958333,\n",
       "        0.72916667, 0.71875   , 0.70833333, 0.75      , 0.77083333,\n",
       "        0.6875    , 0.77083333, 0.75      , 0.73958333, 0.78125   ,\n",
       "        0.71875   , 0.76041667, 0.78125   , 0.77083333, 0.79166667,\n",
       "        0.66666667, 0.72916667, 0.72916667, 0.79166667, 0.78125   ,\n",
       "        0.71875   , 0.79166667, 0.76041667, 0.73958333, 0.78125   ,\n",
       "        0.76041667, 0.77083333, 0.69791667, 0.78125   , 0.78125   ,\n",
       "        0.69791667, 0.78125   , 0.73958333, 0.78125   , 0.73958333,\n",
       "        0.65625   , 0.70833333, 0.72916667, 0.73958333, 0.6875    ,\n",
       "        0.69791667, 0.71875   , 0.75      , 0.75      , 0.78125   ,\n",
       "        0.75      , 0.77083333, 0.78125   , 0.72916667, 0.77083333,\n",
       "        0.73958333, 0.77083333, 0.75      , 0.73958333, 0.76041667,\n",
       "        0.73958333, 0.67708333, 0.75      , 0.71875   , 0.72916667,\n",
       "        0.79166667, 0.63541667, 0.71875   , 0.67708333, 0.71875   ,\n",
       "        0.70833333, 0.75      , 0.8125    , 0.76041667, 0.71875   ,\n",
       "        0.71875   , 0.73958333, 0.73958333, 0.75      , 0.78125   ,\n",
       "        0.75      , 0.64583333, 0.72916667, 0.76041667, 0.71875   ,\n",
       "        0.72916667, 0.75      , 0.72916667, 0.71875   , 0.72916667,\n",
       "        0.71875   , 0.71875   , 0.73958333, 0.78125   , 0.76041667,\n",
       "        0.75      , 0.73958333, 0.77083333, 0.75      , 0.75      ,\n",
       "        0.78125   , 0.76041667, 0.71875   , 0.72916667, 0.79166667,\n",
       "        0.67708333, 0.75      , 0.72916667, 0.77083333, 0.76041667,\n",
       "        0.71875   , 0.75      , 0.76041667, 0.77083333, 0.78125   ,\n",
       "        0.69791667, 0.76041667, 0.76041667, 0.76041667, 0.76041667,\n",
       "        0.72916667, 0.72916667, 0.72916667, 0.77083333, 0.76041667,\n",
       "        0.6875    , 0.76041667, 0.79166667, 0.73958333, 0.71875   ,\n",
       "        0.82291667, 0.71875   , 0.77083333, 0.76041667, 0.73958333,\n",
       "        0.6875    , 0.72916667, 0.75      , 0.70833333, 0.72916667,\n",
       "        0.73958333, 0.72916667, 0.70833333, 0.75      , 0.77083333,\n",
       "        0.76041667, 0.72916667, 0.75      , 0.79166667, 0.69791667,\n",
       "        0.63541667, 0.69791667, 0.75      , 0.72916667, 0.73958333,\n",
       "        0.70833333, 0.73958333, 0.73958333, 0.72916667, 0.76041667,\n",
       "        0.71875   , 0.70833333, 0.69791667, 0.75      , 0.73958333,\n",
       "        0.69791667, 0.6875    , 0.73958333, 0.77083333, 0.75      ,\n",
       "        0.71875   , 0.71875   , 0.72916667, 0.76041667, 0.78125   ,\n",
       "        0.75      , 0.72916667, 0.76041667, 0.77083333, 0.78125   ,\n",
       "        0.72916667, 0.78125   , 0.76041667, 0.78125   , 0.77083333,\n",
       "        0.70833333, 0.78125   , 0.76041667, 0.76041667, 0.76041667,\n",
       "        0.71875   , 0.78125   , 0.78125   , 0.76041667, 0.78125   ,\n",
       "        0.72916667, 0.78125   , 0.71875   , 0.80208333, 0.78125   ,\n",
       "        0.78125   , 0.73958333, 0.78125   , 0.76041667, 0.76041667,\n",
       "        0.73958333, 0.70833333, 0.72916667, 0.69791667, 0.71875   ,\n",
       "        0.69791667, 0.71875   , 0.78125   , 0.72916667, 0.77083333,\n",
       "        0.66666667, 0.69791667, 0.73958333, 0.76041667, 0.73958333,\n",
       "        0.70833333, 0.77083333, 0.78125   , 0.76041667, 0.75      ,\n",
       "        0.70833333, 0.78125   , 0.77083333, 0.75      , 0.77083333,\n",
       "        0.70833333, 0.79166667, 0.73958333, 0.77083333, 0.77083333,\n",
       "        0.65625   , 0.70833333, 0.72916667, 0.75      , 0.73958333,\n",
       "        0.65625   , 0.73958333, 0.75      , 0.77083333, 0.73958333,\n",
       "        0.76041667, 0.6875    , 0.71875   , 0.79166667, 0.77083333,\n",
       "        0.75      , 0.71875   , 0.75      , 0.76041667, 0.73958333,\n",
       "        0.72916667, 0.77083333, 0.72916667, 0.77083333, 0.75      ,\n",
       "        0.70833333, 0.78125   , 0.76041667, 0.78125   , 0.72916667,\n",
       "        0.71875   , 0.72916667, 0.76041667, 0.78125   , 0.73958333,\n",
       "        0.69791667, 0.78125   , 0.76041667, 0.79166667, 0.76041667,\n",
       "        0.72916667, 0.76041667, 0.78125   , 0.79166667, 0.77083333,\n",
       "        0.6875    , 0.77083333, 0.71875   , 0.78125   , 0.70833333,\n",
       "        0.67708333, 0.76041667, 0.75      , 0.69791667, 0.76041667,\n",
       "        0.8125    , 0.75      , 0.76041667, 0.76041667, 0.76041667,\n",
       "        0.73958333, 0.76041667, 0.78125   , 0.78125   , 0.73958333,\n",
       "        0.73958333, 0.72916667, 0.73958333, 0.72916667, 0.77083333,\n",
       "        0.72916667, 0.6875    , 0.76041667, 0.73958333, 0.73958333,\n",
       "        0.73958333, 0.72916667, 0.76041667, 0.72916667, 0.75      ,\n",
       "        0.77083333, 0.76041667, 0.78125   , 0.73958333, 0.71875   ,\n",
       "        0.75      , 0.73958333, 0.78125   , 0.77083333, 0.72916667,\n",
       "        0.70833333, 0.76041667, 0.75      , 0.76041667, 0.72916667,\n",
       "        0.72916667, 0.71875   , 0.75      , 0.79166667, 0.79166667,\n",
       "        0.78125   , 0.72916667, 0.77083333, 0.77083333, 0.75      ,\n",
       "        0.76041667, 0.65625   , 0.75      , 0.75      , 0.78125   ,\n",
       "        0.65625   , 0.6875    , 0.77083333, 0.75      , 0.76041667,\n",
       "        0.76041667, 0.71875   , 0.76041667, 0.76041667, 0.75      ,\n",
       "        0.71875   , 0.78125   , 0.75      , 0.78125   , 0.73958333,\n",
       "        0.67708333, 0.63541667, 0.73958333, 0.71875   , 0.77083333,\n",
       "        0.73958333, 0.77083333, 0.69791667, 0.76041667, 0.71875   ,\n",
       "        0.75      , 0.77083333, 0.79166667, 0.71875   , 0.75      ,\n",
       "        0.82291667, 0.75      , 0.73958333, 0.73958333, 0.73958333,\n",
       "        0.69791667, 0.64583333, 0.75      , 0.72916667, 0.73958333,\n",
       "        0.73958333, 0.78125   , 0.77083333, 0.73958333, 0.79166667,\n",
       "        0.65625   , 0.77083333, 0.75      , 0.76041667, 0.77083333,\n",
       "        0.77083333, 0.71875   , 0.73958333, 0.77083333, 0.73958333,\n",
       "        0.66666667, 0.76041667, 0.73958333, 0.80208333, 0.80208333,\n",
       "        0.72916667, 0.77083333, 0.69791667, 0.73958333, 0.75      ,\n",
       "        0.71875   , 0.70833333, 0.77083333, 0.75      , 0.79166667,\n",
       "        0.75      , 0.70833333, 0.76041667, 0.73958333, 0.78125   ,\n",
       "        0.66666667, 0.67708333, 0.78125   , 0.73958333, 0.79166667,\n",
       "        0.72916667, 0.78125   , 0.77083333, 0.77083333, 0.75      ,\n",
       "        0.71875   , 0.77083333, 0.73958333, 0.77083333, 0.76041667,\n",
       "        0.70833333, 0.73958333, 0.79166667, 0.76041667, 0.78125   ,\n",
       "        0.80208333, 0.75      , 0.71875   , 0.72916667, 0.75      ,\n",
       "        0.65625   , 0.76041667, 0.76041667, 0.73958333, 0.70833333,\n",
       "        0.80208333, 0.70833333, 0.77083333, 0.73958333, 0.75      ,\n",
       "        0.78125   , 0.67708333, 0.77083333, 0.70833333, 0.77083333,\n",
       "        0.72916667, 0.69791667, 0.76041667, 0.71875   , 0.75      ,\n",
       "        0.66666667, 0.76041667, 0.73958333, 0.73958333, 0.77083333,\n",
       "        0.72916667, 0.80208333, 0.77083333, 0.73958333, 0.77083333,\n",
       "        0.69791667, 0.72916667, 0.77083333, 0.72916667, 0.75      ]),\n",
       " 'split4_test_score': array([0.77083333, 0.75      , 0.67708333, 0.70833333, 0.69791667,\n",
       "        0.70833333, 0.66666667, 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.75      , 0.72916667, 0.69791667, 0.70833333, 0.71875   ,\n",
       "        0.71875   , 0.69791667, 0.76041667, 0.71875   , 0.69791667,\n",
       "        0.75      , 0.76041667, 0.71875   , 0.73958333, 0.70833333,\n",
       "        0.69791667, 0.625     , 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.61458333, 0.72916667, 0.70833333, 0.75      , 0.70833333,\n",
       "        0.67708333, 0.66666667, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.66666667, 0.6875    , 0.66666667, 0.71875   , 0.71875   ,\n",
       "        0.6875    , 0.69791667, 0.65625   , 0.72916667, 0.70833333,\n",
       "        0.63541667, 0.71875   , 0.67708333, 0.67708333, 0.69791667,\n",
       "        0.73958333, 0.59375   , 0.66666667, 0.69791667, 0.69791667,\n",
       "        0.69791667, 0.70833333, 0.77083333, 0.67708333, 0.67708333,\n",
       "        0.70833333, 0.75      , 0.76041667, 0.71875   , 0.72916667,\n",
       "        0.70833333, 0.60416667, 0.64583333, 0.64583333, 0.70833333,\n",
       "        0.60416667, 0.60416667, 0.64583333, 0.71875   , 0.70833333,\n",
       "        0.66666667, 0.63541667, 0.67708333, 0.73958333, 0.73958333,\n",
       "        0.69791667, 0.69791667, 0.6875    , 0.71875   , 0.69791667,\n",
       "        0.65625   , 0.70833333, 0.67708333, 0.67708333, 0.71875   ,\n",
       "        0.6875    , 0.70833333, 0.67708333, 0.69791667, 0.72916667,\n",
       "        0.69791667, 0.73958333, 0.72916667, 0.72916667, 0.70833333,\n",
       "        0.69791667, 0.70833333, 0.72916667, 0.71875   , 0.69791667,\n",
       "        0.72916667, 0.72916667, 0.71875   , 0.69791667, 0.70833333,\n",
       "        0.75      , 0.75      , 0.69791667, 0.75      , 0.71875   ,\n",
       "        0.66666667, 0.66666667, 0.64583333, 0.72916667, 0.70833333,\n",
       "        0.73958333, 0.70833333, 0.71875   , 0.71875   , 0.72916667,\n",
       "        0.69791667, 0.6875    , 0.66666667, 0.77083333, 0.70833333,\n",
       "        0.76041667, 0.70833333, 0.69791667, 0.70833333, 0.71875   ,\n",
       "        0.73958333, 0.71875   , 0.625     , 0.70833333, 0.67708333,\n",
       "        0.72916667, 0.70833333, 0.75      , 0.66666667, 0.72916667,\n",
       "        0.66666667, 0.73958333, 0.75      , 0.625     , 0.71875   ,\n",
       "        0.64583333, 0.60416667, 0.65625   , 0.69791667, 0.72916667,\n",
       "        0.64583333, 0.67708333, 0.73958333, 0.71875   , 0.71875   ,\n",
       "        0.58333333, 0.75      , 0.6875    , 0.67708333, 0.69791667,\n",
       "        0.70833333, 0.64583333, 0.69791667, 0.6875    , 0.6875    ,\n",
       "        0.77083333, 0.66666667, 0.67708333, 0.72916667, 0.67708333,\n",
       "        0.60416667, 0.70833333, 0.69791667, 0.75      , 0.70833333,\n",
       "        0.76041667, 0.6875    , 0.77083333, 0.67708333, 0.70833333,\n",
       "        0.77083333, 0.67708333, 0.69791667, 0.71875   , 0.72916667,\n",
       "        0.64583333, 0.66666667, 0.66666667, 0.71875   , 0.70833333,\n",
       "        0.64583333, 0.70833333, 0.6875    , 0.70833333, 0.69791667,\n",
       "        0.69791667, 0.75      , 0.75      , 0.70833333, 0.72916667,\n",
       "        0.60416667, 0.73958333, 0.67708333, 0.70833333, 0.71875   ,\n",
       "        0.6875    , 0.72916667, 0.71875   , 0.70833333, 0.67708333,\n",
       "        0.70833333, 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.79166667, 0.71875   , 0.61458333, 0.69791667, 0.72916667,\n",
       "        0.61458333, 0.78125   , 0.65625   , 0.67708333, 0.6875    ,\n",
       "        0.58333333, 0.66666667, 0.6875    , 0.64583333, 0.72916667,\n",
       "        0.6875    , 0.70833333, 0.76041667, 0.70833333, 0.69791667,\n",
       "        0.70833333, 0.72916667, 0.69791667, 0.67708333, 0.70833333,\n",
       "        0.70833333, 0.65625   , 0.71875   , 0.69791667, 0.6875    ,\n",
       "        0.75      , 0.75      , 0.69791667, 0.71875   , 0.71875   ,\n",
       "        0.69791667, 0.71875   , 0.69791667, 0.6875    , 0.72916667,\n",
       "        0.67708333, 0.65625   , 0.67708333, 0.72916667, 0.66666667,\n",
       "        0.76041667, 0.63541667, 0.69791667, 0.69791667, 0.73958333,\n",
       "        0.70833333, 0.70833333, 0.65625   , 0.71875   , 0.70833333,\n",
       "        0.63541667, 0.71875   , 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.70833333, 0.70833333, 0.78125   , 0.70833333, 0.71875   ,\n",
       "        0.72916667, 0.73958333, 0.70833333, 0.76041667, 0.69791667,\n",
       "        0.67708333, 0.71875   , 0.75      , 0.71875   , 0.70833333,\n",
       "        0.55208333, 0.70833333, 0.70833333, 0.71875   , 0.70833333,\n",
       "        0.66666667, 0.70833333, 0.625     , 0.69791667, 0.67708333,\n",
       "        0.71875   , 0.65625   , 0.71875   , 0.63541667, 0.70833333,\n",
       "        0.66666667, 0.71875   , 0.72916667, 0.71875   , 0.73958333,\n",
       "        0.6875    , 0.70833333, 0.69791667, 0.71875   , 0.71875   ,\n",
       "        0.6875    , 0.71875   , 0.69791667, 0.69791667, 0.70833333,\n",
       "        0.65625   , 0.66666667, 0.70833333, 0.6875    , 0.6875    ,\n",
       "        0.65625   , 0.65625   , 0.71875   , 0.66666667, 0.69791667,\n",
       "        0.75      , 0.6875    , 0.69791667, 0.75      , 0.71875   ,\n",
       "        0.64583333, 0.73958333, 0.73958333, 0.70833333, 0.67708333,\n",
       "        0.69791667, 0.70833333, 0.73958333, 0.73958333, 0.72916667,\n",
       "        0.6875    , 0.67708333, 0.69791667, 0.71875   , 0.72916667,\n",
       "        0.66666667, 0.67708333, 0.75      , 0.72916667, 0.72916667,\n",
       "        0.67708333, 0.71875   , 0.71875   , 0.72916667, 0.71875   ,\n",
       "        0.67708333, 0.63541667, 0.72916667, 0.70833333, 0.77083333,\n",
       "        0.75      , 0.6875    , 0.73958333, 0.76041667, 0.72916667,\n",
       "        0.67708333, 0.69791667, 0.75      , 0.6875    , 0.72916667,\n",
       "        0.69791667, 0.70833333, 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.70833333, 0.70833333, 0.72916667, 0.72916667, 0.72916667,\n",
       "        0.70833333, 0.71875   , 0.71875   , 0.77083333, 0.75      ,\n",
       "        0.58333333, 0.70833333, 0.70833333, 0.71875   , 0.73958333,\n",
       "        0.72916667, 0.69791667, 0.70833333, 0.75      , 0.71875   ,\n",
       "        0.72916667, 0.67708333, 0.6875    , 0.6875    , 0.70833333,\n",
       "        0.76041667, 0.69791667, 0.69791667, 0.6875    , 0.71875   ,\n",
       "        0.73958333, 0.69791667, 0.69791667, 0.71875   , 0.69791667,\n",
       "        0.6875    , 0.6875    , 0.75      , 0.69791667, 0.72916667,\n",
       "        0.6875    , 0.6875    , 0.75      , 0.73958333, 0.70833333,\n",
       "        0.67708333, 0.6875    , 0.72916667, 0.73958333, 0.72916667,\n",
       "        0.77083333, 0.6875    , 0.71875   , 0.72916667, 0.72916667,\n",
       "        0.65625   , 0.61458333, 0.76041667, 0.71875   , 0.70833333,\n",
       "        0.72916667, 0.73958333, 0.75      , 0.71875   , 0.70833333,\n",
       "        0.63541667, 0.71875   , 0.72916667, 0.71875   , 0.72916667,\n",
       "        0.69791667, 0.66666667, 0.6875    , 0.72916667, 0.71875   ,\n",
       "        0.64583333, 0.65625   , 0.72916667, 0.6875    , 0.70833333,\n",
       "        0.69791667, 0.75      , 0.625     , 0.73958333, 0.70833333,\n",
       "        0.58333333, 0.73958333, 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.63541667, 0.625     , 0.71875   , 0.71875   , 0.71875   ,\n",
       "        0.6875    , 0.6875    , 0.69791667, 0.71875   , 0.72916667,\n",
       "        0.71875   , 0.72916667, 0.70833333, 0.69791667, 0.71875   ,\n",
       "        0.66666667, 0.6875    , 0.71875   , 0.70833333, 0.70833333,\n",
       "        0.65625   , 0.66666667, 0.71875   , 0.71875   , 0.70833333,\n",
       "        0.69791667, 0.65625   , 0.75      , 0.70833333, 0.70833333,\n",
       "        0.70833333, 0.69791667, 0.71875   , 0.72916667, 0.6875    ,\n",
       "        0.71875   , 0.71875   , 0.72916667, 0.72916667, 0.71875   ,\n",
       "        0.67708333, 0.70833333, 0.76041667, 0.73958333, 0.75      ,\n",
       "        0.64583333, 0.67708333, 0.69791667, 0.72916667, 0.72916667,\n",
       "        0.71875   , 0.69791667, 0.70833333, 0.70833333, 0.73958333,\n",
       "        0.71875   , 0.66666667, 0.70833333, 0.72916667, 0.72916667,\n",
       "        0.69791667, 0.71875   , 0.72916667, 0.67708333, 0.72916667,\n",
       "        0.60416667, 0.65625   , 0.64583333, 0.67708333, 0.72916667,\n",
       "        0.63541667, 0.73958333, 0.70833333, 0.75      , 0.63541667,\n",
       "        0.71875   , 0.69791667, 0.73958333, 0.71875   , 0.65625   ,\n",
       "        0.63541667, 0.63541667, 0.69791667, 0.69791667, 0.69791667,\n",
       "        0.64583333, 0.625     , 0.69791667, 0.71875   , 0.70833333,\n",
       "        0.64583333, 0.70833333, 0.71875   , 0.70833333, 0.71875   ,\n",
       "        0.70833333, 0.66666667, 0.71875   , 0.70833333, 0.69791667,\n",
       "        0.67708333, 0.72916667, 0.70833333, 0.73958333, 0.71875   ,\n",
       "        0.72916667, 0.69791667, 0.71875   , 0.6875    , 0.69791667,\n",
       "        0.59375   , 0.70833333, 0.70833333, 0.70833333, 0.71875   ,\n",
       "        0.71875   , 0.76041667, 0.72916667, 0.67708333, 0.70833333,\n",
       "        0.63541667, 0.70833333, 0.70833333, 0.72916667, 0.70833333,\n",
       "        0.69791667, 0.69791667, 0.65625   , 0.70833333, 0.71875   ,\n",
       "        0.64583333, 0.76041667, 0.72916667, 0.70833333, 0.70833333,\n",
       "        0.72916667, 0.73958333, 0.73958333, 0.72916667, 0.72916667,\n",
       "        0.78125   , 0.65625   , 0.77083333, 0.69791667, 0.73958333,\n",
       "        0.61458333, 0.67708333, 0.71875   , 0.72916667, 0.70833333,\n",
       "        0.69791667, 0.70833333, 0.66666667, 0.6875    , 0.70833333,\n",
       "        0.71875   , 0.69791667, 0.72916667, 0.70833333, 0.70833333]),\n",
       " 'mean_test_score': array([0.66875   , 0.65833333, 0.68333333, 0.69166667, 0.68541667,\n",
       "        0.67291667, 0.66041667, 0.67291667, 0.68125   , 0.67083333,\n",
       "        0.65      , 0.72708333, 0.68125   , 0.69375   , 0.68333333,\n",
       "        0.68541667, 0.68541667, 0.69375   , 0.7       , 0.68958333,\n",
       "        0.6875    , 0.71875   , 0.7       , 0.7       , 0.70416667,\n",
       "        0.64166667, 0.65833333, 0.70208333, 0.69791667, 0.69375   ,\n",
       "        0.63541667, 0.68125   , 0.68541667, 0.71458333, 0.69583333,\n",
       "        0.67083333, 0.66458333, 0.70208333, 0.70416667, 0.7       ,\n",
       "        0.67083333, 0.71458333, 0.69166667, 0.68958333, 0.69791667,\n",
       "        0.68541667, 0.68958333, 0.68333333, 0.70208333, 0.69166667,\n",
       "        0.65833333, 0.68541667, 0.68541667, 0.68333333, 0.70416667,\n",
       "        0.69375   , 0.66875   , 0.69166667, 0.69791667, 0.70416667,\n",
       "        0.68333333, 0.67916667, 0.71666667, 0.69583333, 0.68333333,\n",
       "        0.67291667, 0.70416667, 0.68125   , 0.69166667, 0.6875    ,\n",
       "        0.68541667, 0.65625   , 0.68958333, 0.6875    , 0.69375   ,\n",
       "        0.675     , 0.675     , 0.6875    , 0.68541667, 0.69166667,\n",
       "        0.6625    , 0.67291667, 0.68541667, 0.675     , 0.68541667,\n",
       "        0.65833333, 0.67291667, 0.68125   , 0.70625   , 0.68541667,\n",
       "        0.6375    , 0.67291667, 0.67291667, 0.68541667, 0.69166667,\n",
       "        0.64583333, 0.69375   , 0.67291667, 0.68958333, 0.70625   ,\n",
       "        0.68333333, 0.68541667, 0.70416667, 0.69375   , 0.68958333,\n",
       "        0.65416667, 0.6875    , 0.68958333, 0.7       , 0.69375   ,\n",
       "        0.67083333, 0.69166667, 0.70833333, 0.6875    , 0.69375   ,\n",
       "        0.66875   , 0.7125    , 0.69583333, 0.70625   , 0.69583333,\n",
       "        0.67708333, 0.70625   , 0.67708333, 0.69166667, 0.7       ,\n",
       "        0.66458333, 0.71875   , 0.70208333, 0.69166667, 0.71041667,\n",
       "        0.70416667, 0.69583333, 0.66666667, 0.7       , 0.7       ,\n",
       "        0.66458333, 0.6875    , 0.70625   , 0.69791667, 0.68541667,\n",
       "        0.69375   , 0.67083333, 0.66666667, 0.71041667, 0.68125   ,\n",
       "        0.7125    , 0.69375   , 0.69166667, 0.67083333, 0.6875    ,\n",
       "        0.67083333, 0.7125    , 0.71041667, 0.66458333, 0.69166667,\n",
       "        0.65      , 0.6625    , 0.68125   , 0.68333333, 0.7       ,\n",
       "        0.65      , 0.65833333, 0.67916667, 0.68541667, 0.67708333,\n",
       "        0.6375    , 0.68333333, 0.6875    , 0.68333333, 0.6875    ,\n",
       "        0.65      , 0.65      , 0.69583333, 0.6875    , 0.68125   ,\n",
       "        0.6875    , 0.69375   , 0.68958333, 0.70833333, 0.69791667,\n",
       "        0.6125    , 0.70208333, 0.67916667, 0.70208333, 0.70416667,\n",
       "        0.70208333, 0.68333333, 0.725     , 0.68333333, 0.69583333,\n",
       "        0.68958333, 0.675     , 0.675     , 0.70625   , 0.68958333,\n",
       "        0.65      , 0.70833333, 0.68125   , 0.70625   , 0.69166667,\n",
       "        0.65625   , 0.68125   , 0.6875    , 0.69166667, 0.68958333,\n",
       "        0.69375   , 0.70208333, 0.71875   , 0.69583333, 0.70416667,\n",
       "        0.67291667, 0.71875   , 0.69583333, 0.68541667, 0.69583333,\n",
       "        0.6625    , 0.69583333, 0.7125    , 0.68958333, 0.68958333,\n",
       "        0.71458333, 0.69166667, 0.69583333, 0.69166667, 0.68958333,\n",
       "        0.70625   , 0.66666667, 0.66666667, 0.675     , 0.69791667,\n",
       "        0.64375   , 0.71875   , 0.68541667, 0.67083333, 0.68125   ,\n",
       "        0.63125   , 0.70208333, 0.70833333, 0.66458333, 0.70208333,\n",
       "        0.6625    , 0.65      , 0.67083333, 0.68333333, 0.67916667,\n",
       "        0.67083333, 0.68125   , 0.67916667, 0.6875    , 0.6875    ,\n",
       "        0.66458333, 0.66875   , 0.67916667, 0.69375   , 0.6875    ,\n",
       "        0.71458333, 0.67291667, 0.68958333, 0.6875    , 0.69375   ,\n",
       "        0.68125   , 0.69791667, 0.6875    , 0.69583333, 0.7       ,\n",
       "        0.66458333, 0.66041667, 0.6875    , 0.69791667, 0.68333333,\n",
       "        0.69375   , 0.69166667, 0.6875    , 0.69166667, 0.71666667,\n",
       "        0.67916667, 0.6875    , 0.67083333, 0.70833333, 0.69791667,\n",
       "        0.68125   , 0.69375   , 0.70833333, 0.69375   , 0.69791667,\n",
       "        0.65625   , 0.69375   , 0.71875   , 0.68958333, 0.68958333,\n",
       "        0.68958333, 0.70208333, 0.70208333, 0.70416667, 0.70416667,\n",
       "        0.67916667, 0.68541667, 0.7       , 0.69791667, 0.68958333,\n",
       "        0.63541667, 0.71666667, 0.68333333, 0.69166667, 0.69375   ,\n",
       "        0.69375   , 0.70625   , 0.67083333, 0.69583333, 0.67708333,\n",
       "        0.66875   , 0.67291667, 0.7       , 0.69583333, 0.68333333,\n",
       "        0.68333333, 0.69166667, 0.69583333, 0.6875    , 0.70208333,\n",
       "        0.65625   , 0.67291667, 0.67083333, 0.66875   , 0.68958333,\n",
       "        0.68125   , 0.65833333, 0.66875   , 0.69166667, 0.67916667,\n",
       "        0.67916667, 0.65416667, 0.67291667, 0.68125   , 0.68333333,\n",
       "        0.66041667, 0.675     , 0.68958333, 0.68333333, 0.69583333,\n",
       "        0.67291667, 0.67708333, 0.69583333, 0.7       , 0.69166667,\n",
       "        0.66041667, 0.69583333, 0.69375   , 0.67916667, 0.68125   ,\n",
       "        0.67708333, 0.70416667, 0.69166667, 0.7       , 0.70208333,\n",
       "        0.66666667, 0.69166667, 0.66666667, 0.71666667, 0.69791667,\n",
       "        0.67291667, 0.68541667, 0.69791667, 0.69375   , 0.69375   ,\n",
       "        0.67291667, 0.67083333, 0.6875    , 0.68125   , 0.675     ,\n",
       "        0.65208333, 0.675     , 0.69166667, 0.67916667, 0.71875   ,\n",
       "        0.6875    , 0.68125   , 0.69583333, 0.70833333, 0.69166667,\n",
       "        0.66875   , 0.68958333, 0.70833333, 0.68125   , 0.69375   ,\n",
       "        0.66875   , 0.69791667, 0.69166667, 0.70416667, 0.69583333,\n",
       "        0.67708333, 0.70625   , 0.69583333, 0.69166667, 0.69375   ,\n",
       "        0.68333333, 0.7       , 0.70208333, 0.7       , 0.7       ,\n",
       "        0.6375    , 0.6875    , 0.67916667, 0.7       , 0.68541667,\n",
       "        0.68541667, 0.66666667, 0.68541667, 0.69791667, 0.67916667,\n",
       "        0.68333333, 0.69791667, 0.69166667, 0.70208333, 0.67708333,\n",
       "        0.68541667, 0.69375   , 0.69583333, 0.6875    , 0.69583333,\n",
       "        0.68541667, 0.69583333, 0.69583333, 0.7       , 0.69375   ,\n",
       "        0.6875    , 0.67708333, 0.70833333, 0.69791667, 0.69375   ,\n",
       "        0.65833333, 0.70833333, 0.70625   , 0.7125    , 0.6875    ,\n",
       "        0.68541667, 0.6625    , 0.70416667, 0.71458333, 0.70416667,\n",
       "        0.68125   , 0.69166667, 0.68333333, 0.69375   , 0.67916667,\n",
       "        0.6625    , 0.66666667, 0.69583333, 0.67708333, 0.69166667,\n",
       "        0.68541667, 0.69166667, 0.70208333, 0.68958333, 0.69166667,\n",
       "        0.66666667, 0.675     , 0.70625   , 0.69791667, 0.6875    ,\n",
       "        0.69375   , 0.7       , 0.6875    , 0.675     , 0.69375   ,\n",
       "        0.68125   , 0.68958333, 0.70416667, 0.6875    , 0.68541667,\n",
       "        0.68541667, 0.70208333, 0.65833333, 0.69375   , 0.68333333,\n",
       "        0.6625    , 0.70833333, 0.70625   , 0.68958333, 0.69166667,\n",
       "        0.65416667, 0.66041667, 0.70416667, 0.69791667, 0.68125   ,\n",
       "        0.67291667, 0.67916667, 0.68333333, 0.70833333, 0.69791667,\n",
       "        0.65625   , 0.69166667, 0.6875    , 0.7       , 0.7       ,\n",
       "        0.70416667, 0.68958333, 0.68541667, 0.69375   , 0.69583333,\n",
       "        0.68541667, 0.6625    , 0.67916667, 0.68541667, 0.69166667,\n",
       "        0.65625   , 0.65833333, 0.71666667, 0.68958333, 0.69166667,\n",
       "        0.69583333, 0.66458333, 0.69791667, 0.68958333, 0.67708333,\n",
       "        0.67291667, 0.70208333, 0.69166667, 0.69375   , 0.70416667,\n",
       "        0.65416667, 0.66041667, 0.69583333, 0.68541667, 0.7       ,\n",
       "        0.67291667, 0.68958333, 0.66875   , 0.70625   , 0.67916667,\n",
       "        0.68541667, 0.69375   , 0.70416667, 0.68958333, 0.71041667,\n",
       "        0.69166667, 0.675     , 0.68125   , 0.69375   , 0.675     ,\n",
       "        0.65416667, 0.65416667, 0.69583333, 0.68333333, 0.69166667,\n",
       "        0.66875   , 0.675     , 0.69375   , 0.68541667, 0.70208333,\n",
       "        0.65625   , 0.71458333, 0.70416667, 0.70416667, 0.675     ,\n",
       "        0.68125   , 0.64583333, 0.68958333, 0.7       , 0.67916667,\n",
       "        0.63333333, 0.66458333, 0.67708333, 0.69375   , 0.67708333,\n",
       "        0.64791667, 0.66041667, 0.67083333, 0.6875    , 0.67708333,\n",
       "        0.66666667, 0.67291667, 0.69166667, 0.6875    , 0.70208333,\n",
       "        0.67708333, 0.67291667, 0.7       , 0.68541667, 0.6875    ,\n",
       "        0.66666667, 0.67916667, 0.70625   , 0.68541667, 0.69166667,\n",
       "        0.675     , 0.68958333, 0.6875    , 0.6875    , 0.6875    ,\n",
       "        0.64583333, 0.70208333, 0.70208333, 0.69166667, 0.675     ,\n",
       "        0.68541667, 0.7       , 0.69583333, 0.68541667, 0.7       ,\n",
       "        0.68125   , 0.67083333, 0.6875    , 0.69166667, 0.69375   ,\n",
       "        0.64375   , 0.68541667, 0.67291667, 0.69375   , 0.68541667,\n",
       "        0.68958333, 0.69791667, 0.7       , 0.68958333, 0.69166667,\n",
       "        0.69166667, 0.70625   , 0.69166667, 0.68958333, 0.69791667,\n",
       "        0.67291667, 0.64375   , 0.71458333, 0.67708333, 0.69166667,\n",
       "        0.67083333, 0.70208333, 0.7       , 0.68541667, 0.69791667,\n",
       "        0.66875   , 0.68125   , 0.68958333, 0.69166667, 0.69583333,\n",
       "        0.67708333, 0.6875    , 0.71666667, 0.675     , 0.68958333]),\n",
       " 'std_test_score': array([0.05120086, 0.07015608, 0.04448783, 0.04868051, 0.05245699,\n",
       "        0.02243819, 0.01816208, 0.04592793, 0.06305311, 0.0557462 ,\n",
       "        0.06095308, 0.03510896, 0.02841288, 0.05803495, 0.05456584,\n",
       "        0.02224391, 0.01530931, 0.05535554, 0.06123724, 0.05162297,\n",
       "        0.05705443, 0.03952847, 0.03632416, 0.05162297, 0.04686342,\n",
       "        0.05416667, 0.03691676, 0.04956407, 0.0372678 , 0.03644345,\n",
       "        0.04516559, 0.03333333, 0.02319902, 0.04545297, 0.03864008,\n",
       "        0.03461093, 0.02124591, 0.02990146, 0.05043216, 0.04535738,\n",
       "        0.01412985, 0.0477806 , 0.03644345, 0.0463044 , 0.03486083,\n",
       "        0.03186887, 0.04535738, 0.05803495, 0.04145781, 0.041978  ,\n",
       "        0.03118048, 0.03320287, 0.02319902, 0.03333333, 0.03818813,\n",
       "        0.02841288, 0.0463044 , 0.02841288, 0.04658475, 0.04686342,\n",
       "        0.03200477, 0.03385016, 0.04238956, 0.04082483, 0.03333333,\n",
       "        0.08528954, 0.04093101, 0.06541799, 0.04686342, 0.04320092,\n",
       "        0.04991312, 0.03227486, 0.05120086, 0.03547789, 0.04145781,\n",
       "        0.0669914 , 0.06827487, 0.03159531, 0.05488308, 0.04039733,\n",
       "        0.08296795, 0.05803495, 0.0463044 , 0.05943893, 0.05162297,\n",
       "        0.05870418, 0.02684187, 0.04145781, 0.05720638, 0.05368374,\n",
       "        0.02019867, 0.02763854, 0.03761556, 0.05245699, 0.05803495,\n",
       "        0.05743354, 0.05690208, 0.05043216, 0.05162297, 0.0344853 ,\n",
       "        0.04497299, 0.05077524, 0.041978  , 0.05690208, 0.04028975,\n",
       "        0.04768968, 0.04796194, 0.04289846, 0.04859127, 0.03333333,\n",
       "        0.04145781, 0.04093101, 0.03359274, 0.04796194, 0.03267581,\n",
       "        0.08395601, 0.04299952, 0.03919768, 0.05245699, 0.04768968,\n",
       "        0.0372678 , 0.02411633, 0.04419417, 0.03875224, 0.03385016,\n",
       "        0.06535161, 0.03227486, 0.04399732, 0.03930825, 0.04082483,\n",
       "        0.04039733, 0.02748105, 0.03019037, 0.05034602, 0.04991312,\n",
       "        0.08265348, 0.0389756 , 0.04028975, 0.03668087, 0.04723243,\n",
       "        0.04956407, 0.03397814, 0.03784563, 0.05644257, 0.05335937,\n",
       "        0.0529511 , 0.0576598 , 0.04093101, 0.01932004, 0.04218428,\n",
       "        0.06130808, 0.04350128, 0.04082483, 0.03691676, 0.05043216,\n",
       "        0.04448783, 0.03875224, 0.05043216, 0.04145781, 0.03632416,\n",
       "        0.00833333, 0.05120086, 0.04487637, 0.04814258, 0.05311479,\n",
       "        0.04991312, 0.04350128, 0.03423266, 0.04350128, 0.05781015,\n",
       "        0.04039733, 0.06737901, 0.03118048, 0.03159531, 0.05535554,\n",
       "        0.05145454, 0.0572822 , 0.0463044 , 0.03784563, 0.05392575,\n",
       "        0.04677072, 0.03584302, 0.03254271, 0.07021791, 0.04249183,\n",
       "        0.03761556, 0.05803495, 0.03584302, 0.03644345, 0.0601647 ,\n",
       "        0.07077203, 0.05162297, 0.025     , 0.04439016, 0.06859199,\n",
       "        0.03761556, 0.04061164, 0.03397814, 0.04535738, 0.02990146,\n",
       "        0.04007372, 0.02763854, 0.03019037, 0.041978  , 0.02901748,\n",
       "        0.02990146, 0.06270799, 0.02871677, 0.03572173, 0.04912428,\n",
       "        0.06130808, 0.04114254, 0.05448624, 0.04340139, 0.04814258,\n",
       "        0.05253967, 0.05368374, 0.03644345, 0.0375    , 0.04082483,\n",
       "        0.01412985, 0.05      , 0.04289846, 0.04399732, 0.0463044 ,\n",
       "        0.08369712, 0.03486083, 0.04061164, 0.02124591, 0.03423266,\n",
       "        0.07077203, 0.04750731, 0.06434769, 0.04912428, 0.03061862,\n",
       "        0.06990817, 0.03761556, 0.03423266, 0.04768968, 0.05212498,\n",
       "        0.05535554, 0.04039733, 0.06339635, 0.04592793, 0.04723243,\n",
       "        0.041978  , 0.05253967, 0.03254271, 0.0186339 , 0.03547789,\n",
       "        0.04028975, 0.025     , 0.04340139, 0.0529511 , 0.0488585 ,\n",
       "        0.03818813, 0.05877807, 0.04991312, 0.04007372, 0.03644345,\n",
       "        0.05613414, 0.0372678 , 0.02083333, 0.0344853 , 0.05408648,\n",
       "        0.01666667, 0.05456584, 0.02375365, 0.05017331, 0.04350128,\n",
       "        0.05376453, 0.03644345, 0.04750731, 0.04497299, 0.04487637,\n",
       "        0.02124591, 0.04516559, 0.04497299, 0.03668087, 0.03784563,\n",
       "        0.03584302, 0.02684187, 0.02282177, 0.05914612, 0.04320092,\n",
       "        0.04841229, 0.04093101, 0.06353313, 0.04535738, 0.02585349,\n",
       "        0.07944032, 0.03267581, 0.05651942, 0.06095308, 0.03200477,\n",
       "        0.00779512, 0.03320287, 0.04723243, 0.02185018, 0.02825971,\n",
       "        0.06718548, 0.01792151, 0.03131937, 0.03875224, 0.04732424,\n",
       "        0.03703414, 0.02901748, 0.04249183, 0.05796012, 0.02551552,\n",
       "        0.04289846, 0.04497299, 0.0375    , 0.0344853 , 0.04868051,\n",
       "        0.02517301, 0.03930825, 0.03919768, 0.04218428, 0.04956407,\n",
       "        0.04114254, 0.03333333, 0.02243819, 0.06468406, 0.03572173,\n",
       "        0.04592793, 0.03864008, 0.04487637, 0.04497299, 0.0463044 ,\n",
       "        0.02667968, 0.04340139, 0.04350128, 0.04299952, 0.0576598 ,\n",
       "        0.05535554, 0.02825971, 0.04723243, 0.04639804, 0.04583333,\n",
       "        0.05651942, 0.05628857, 0.03974747, 0.05488308, 0.0477806 ,\n",
       "        0.02916667, 0.05448624, 0.05212498, 0.04859127, 0.04399732,\n",
       "        0.03294039, 0.04686342, 0.06508541, 0.04340139, 0.04686342,\n",
       "        0.04166667, 0.04639804, 0.03841477, 0.04768968, 0.05060399,\n",
       "        0.05877807, 0.0463044 , 0.06215181, 0.04497299, 0.04299952,\n",
       "        0.05043216, 0.04868051, 0.03159531, 0.02990146, 0.04289846,\n",
       "        0.03131937, 0.05034602, 0.05613414, 0.04028975, 0.04564355,\n",
       "        0.0389756 , 0.01412985, 0.04991312, 0.04320092, 0.04093101,\n",
       "        0.02411633, 0.05644257, 0.04796194, 0.04299952, 0.04639804,\n",
       "        0.05870418, 0.05311479, 0.04686342, 0.02684187, 0.04082483,\n",
       "        0.03423266, 0.05034602, 0.0344853 , 0.05376453, 0.04956407,\n",
       "        0.03397814, 0.02224391, 0.01932004, 0.05034602, 0.04535738,\n",
       "        0.03186887, 0.03423266, 0.04289846, 0.04289846, 0.05566829,\n",
       "        0.05448624, 0.02871677, 0.02901748, 0.06109533, 0.06568284,\n",
       "        0.0477806 , 0.02185018, 0.03267581, 0.02990146, 0.04611655,\n",
       "        0.05488308, 0.04639804, 0.01792151, 0.04419417, 0.03320287,\n",
       "        0.06088183, 0.04487637, 0.03632416, 0.04677072, 0.02517301,\n",
       "        0.03841477, 0.03668087, 0.04061164, 0.04516559, 0.03523236,\n",
       "        0.05943893, 0.04419417, 0.04238956, 0.0477806 , 0.04796194,\n",
       "        0.03974747, 0.05914612, 0.05376453, 0.04592793, 0.04093101,\n",
       "        0.04823265, 0.04497299, 0.02990146, 0.05535554, 0.04028975,\n",
       "        0.02144923, 0.05103104, 0.04903584, 0.03486083, 0.04093101,\n",
       "        0.07465197, 0.04497299, 0.04545297, 0.0463044 , 0.03985651,\n",
       "        0.04750731, 0.06088183, 0.04814258, 0.04750731, 0.04061164,\n",
       "        0.03761556, 0.02224391, 0.03019037, 0.04535738, 0.05376453,\n",
       "        0.03200477, 0.01792151, 0.03644345, 0.04007372, 0.04289846,\n",
       "        0.03691676, 0.04249183, 0.05286907, 0.03761556, 0.04249183,\n",
       "        0.06236096, 0.04370037, 0.04289846, 0.03572173, 0.03061862,\n",
       "        0.05408648, 0.04249183, 0.04299952, 0.06488505, 0.04823265,\n",
       "        0.03930825, 0.05077524, 0.041978  , 0.03090083, 0.03668087,\n",
       "        0.05855612, 0.03131937, 0.04320092, 0.05077524, 0.05077524,\n",
       "        0.04299952, 0.02319902, 0.05605677, 0.04545297, 0.03186887,\n",
       "        0.04082483, 0.02517301, 0.04859127, 0.04535738, 0.05086065,\n",
       "        0.02716334, 0.01792151, 0.03691676, 0.03864008, 0.041978  ,\n",
       "        0.04028975, 0.04340139, 0.03668087, 0.04859127, 0.04166667,\n",
       "        0.04639804, 0.04868051, 0.03985651, 0.06236096, 0.02243819,\n",
       "        0.03632416, 0.04545297, 0.04768968, 0.04487637, 0.05162297,\n",
       "        0.05840769, 0.04289846, 0.02825971, 0.03919768, 0.04135299,\n",
       "        0.05286907, 0.04093101, 0.04639804, 0.025     , 0.03047654,\n",
       "        0.07671647, 0.04535738, 0.03761556, 0.03761556, 0.05720638,\n",
       "        0.06123724, 0.05758448, 0.04340139, 0.02517301, 0.03875224,\n",
       "        0.06400955, 0.05327797, 0.04145781, 0.0344853 , 0.05253967,\n",
       "        0.02551552, 0.04350128, 0.03131937, 0.04497299, 0.05408648,\n",
       "        0.07811806, 0.05781015, 0.04535738, 0.04238956, 0.03320287,\n",
       "        0.02585349, 0.05077524, 0.05145454, 0.05914612, 0.07336174,\n",
       "        0.05527708, 0.06305311, 0.02602082, 0.04750731, 0.04930066,\n",
       "        0.02635231, 0.03333333, 0.04823265, 0.0488585 , 0.0529511 ,\n",
       "        0.04658475, 0.02429563, 0.03864008, 0.0344853 , 0.05187458,\n",
       "        0.01141089, 0.02585349, 0.04187448, 0.05488308, 0.05840769,\n",
       "        0.04535738, 0.05368374, 0.05551214, 0.04564355, 0.03668087,\n",
       "        0.04750731, 0.03818813, 0.02144923, 0.04592793, 0.05527708,\n",
       "        0.02901748, 0.04187448, 0.06263873, 0.03919768, 0.04389856,\n",
       "        0.06130808, 0.05170697, 0.02185018, 0.03333333, 0.03523236,\n",
       "        0.05327797, 0.04677072, 0.0477806 , 0.03397814, 0.02585349,\n",
       "        0.05720638, 0.03668087, 0.04340139, 0.0344853 , 0.03584302,\n",
       "        0.05535554, 0.02825971, 0.06737901, 0.02901748, 0.04750731,\n",
       "        0.07353901, 0.03919768, 0.041978  , 0.02871677, 0.04545297,\n",
       "        0.03584302, 0.04497299, 0.03186887, 0.05204165, 0.04061164,\n",
       "        0.03919768, 0.07021791, 0.04082483, 0.03333333, 0.04991312,\n",
       "        0.05781015, 0.04320092, 0.04535738, 0.04340139, 0.04187448]),\n",
       " 'rank_test_score': array([548, 595, 401, 235, 386, 512, 589, 523, 426, 536, 620,   1, 447,\n",
       "        200, 401, 386, 363, 200, 106, 293, 355,   8, 115, 115,  60, 632,\n",
       "        597,  89, 135, 192, 636, 426, 359,  16, 171, 531, 573,  89,  71,\n",
       "        106, 536,  16, 235, 293, 135, 386, 293, 401,  89, 233, 597, 363,\n",
       "        386, 401,  60, 192, 549, 235, 135,  60, 401, 453,  10, 171, 401,\n",
       "        512,  60, 426, 235, 322, 386, 609, 282, 322, 192, 490, 503, 322,\n",
       "        363, 235, 580, 512, 363, 490, 363, 597, 523, 426,  44, 386, 634,\n",
       "        512, 512, 363, 235, 626, 200, 508, 293,  55, 401, 363,  71, 200,\n",
       "        293, 612, 322, 293, 115, 200, 536, 235,  34, 322, 192, 549,  23,\n",
       "        171,  44, 171, 478,  44, 473, 235, 106, 571,   3,  89, 235,  28,\n",
       "         71, 159, 564, 115, 106, 573, 322,  44, 135, 363, 200, 536, 564,\n",
       "         28, 426,  27, 192, 235, 536, 322, 536,  24,  31, 573, 235, 618,\n",
       "        580, 426, 401, 115, 620, 595, 453, 386, 478, 634, 401, 319, 401,\n",
       "        322, 620, 620, 171, 322, 426, 322, 228, 293,  34, 151, 640,  89,\n",
       "        467,  89,  60,  89, 401,   2, 401, 159, 293, 490, 503,  44, 293,\n",
       "        620,  34, 426,  44, 235, 605, 426, 355, 233, 293, 200,  82,   6,\n",
       "        159,  71, 512,   3, 159, 363, 159, 580, 159,  24, 282, 293,  16,\n",
       "        235, 171, 235, 293,  55, 564, 560, 490, 151, 629,   6, 386, 531,\n",
       "        426, 639,  89,  32, 573,  89, 580, 618, 536, 401, 467, 531, 447,\n",
       "        467, 322, 322, 573, 549, 453, 200, 322,  16, 512, 293, 322, 200,\n",
       "        447, 135, 322, 171, 115, 571, 589, 322, 151, 425, 228, 235, 355,\n",
       "        235,  10, 453, 322, 536,  34, 135, 426, 200,  34, 200, 151, 604,\n",
       "        200,   8, 282, 293, 293,  82,  82,  71,  60, 453, 363, 115, 135,\n",
       "        282, 636,  10, 401, 235, 192, 228,  44, 536, 171, 478, 549, 523,\n",
       "        115, 189, 401, 401, 235, 171, 322,  89, 605, 508, 536, 549, 282,\n",
       "        447, 597, 549, 235, 453, 453, 612, 512, 447, 401, 589, 490, 293,\n",
       "        401, 171, 523, 478, 189, 115, 235, 588, 159, 200, 453, 426, 478,\n",
       "         60, 235, 115,  89, 564, 235, 564,  10, 135, 523, 363, 135, 228,\n",
       "        228, 508, 531, 322, 426, 490, 617, 490, 235, 453,   3, 322, 426,\n",
       "        159,  34, 235, 549, 293,  34, 447, 200, 549, 135, 235,  60, 159,\n",
       "        473,  44, 159, 235, 200, 401, 106,  89, 115, 106, 633, 319, 453,\n",
       "        115, 363, 386, 564, 363, 135, 453, 401, 135, 235,  89, 473, 386,\n",
       "        200, 171, 322, 171, 363, 171, 189, 115, 200, 322, 478,  34, 135,\n",
       "        200, 597,  32,  55,  24, 322, 386, 580,  71,  16,  60, 426, 235,\n",
       "        401, 200, 453, 580, 560, 171, 478, 235, 386, 235,  89, 293, 235,\n",
       "        564, 490,  55, 135, 322, 200, 115, 319, 503, 192, 426, 293,  71,\n",
       "        322, 359, 363,  89, 597, 200, 401, 580,  34,  44, 282, 235, 612,\n",
       "        589,  71, 135, 426, 512, 467, 401,  34, 151, 605, 235, 322, 115,\n",
       "        115,  71, 293, 363, 200, 159, 386, 580, 453, 386, 235, 605, 597,\n",
       "         10, 293, 235, 171, 573, 151, 318, 478, 512,  82, 235, 200,  60,\n",
       "        611, 589, 171, 363, 115, 512, 282, 549,  55, 467, 363, 200,  71,\n",
       "        282,  28, 235, 503, 426, 200, 490, 616, 612, 171, 401, 235, 549,\n",
       "        490, 192, 359,  89, 609,  16,  60,  71, 490, 426, 626, 282, 106,\n",
       "        453, 638, 573, 473, 200, 473, 625, 589, 536, 322, 478, 560, 508,\n",
       "        235, 322,  89, 478, 523, 115, 363, 322, 560, 467,  44, 359, 235,\n",
       "        503, 293, 322, 322, 322, 626,  82,  82, 235, 490, 363, 115, 171,\n",
       "        363, 106, 426, 531, 322, 235, 200, 631, 386, 523, 200, 363, 282,\n",
       "        151, 115, 282, 235, 235,  44, 235, 293, 151, 523, 629,  16, 478,\n",
       "        235, 536,  82, 106, 363, 135, 549, 426, 293, 235, 159, 478, 355,\n",
       "         10, 490, 293])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando os melhores parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando o melhor score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7270833333333333"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
